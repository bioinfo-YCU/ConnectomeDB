{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc5ddc1-519e-439c-a130-3dd8bcd181bd",
   "metadata": {},
   "source": [
    "# Python Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443872e-66e7-427a-a031-75a16471e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(change):\n",
    "    global gene_pair\n",
    "    # Add a new row at the top with None values\n",
    "    new_row = {col: None for col in gene_pair.columns}\n",
    "    gene_pair = pd.DataFrame([new_row] + gene_pair.to_dict(orient=\"records\"))\n",
    "    update_table()\n",
    "\n",
    "# Function to remove the last row of the dataframe\n",
    "def remove_row(change):\n",
    "    global gene_pair\n",
    "    if len(gene_pair) > 0:\n",
    "        gene_pair = gene_pair[:-1]  # Remove the last row\n",
    "        update_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327783b9-5ddf-44d0-8fee-51819b75e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to convert Humans (HGNC symbol) to Other species ID via biomart\n",
    "import os\n",
    "import sys\n",
    "from biomart import BiomartServer\n",
    "import pandas as pd\n",
    "\n",
    "# Add source directory to the path\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "from createDataTable import hgnc_id\n",
    "\n",
    "biomart_server_url = \"http://www.ensembl.org/biomart\"\n",
    "server = BiomartServer(biomart_server_url)\n",
    "# Select zebrafish dataset\n",
    "dataset_name = \"drerio_gene_ensembl\"\n",
    "dataset = server.datasets[dataset_name]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee951fa-0de6-46a3-9e5b-e8a204c89df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to convert Humans (HGNC symbol) to Other species ID via biomart\n",
    "import os\n",
    "import sys\n",
    "from biomart import BiomartServer\n",
    "import pandas as pd\n",
    "\n",
    "# Add source directory to the path\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "from createDataTable import hgnc_id\n",
    "\n",
    "# Species-specific parameters\n",
    "species_id_prefix = \"ZFIN\"  # \"RGD\" for rat, \"MGI\" for mouse\n",
    "dataset_name = \"drerio_gene_ensembl\" # \"drerio_gene_ensembl\" for zebra fish, \"rnorvegicus_gene_ensembl\" for rat, \"mmusculus_gene_ensembl\" for mouse\n",
    "gene_id_field = \"zfin_id\"  # \"external_gene_name\" for mouse\n",
    "gene_symbol_field = \"zfin_symbol\"  # \"external_gene_name\" for mouse\n",
    "output_filename=\"data/hgnc_to_zfin_mapping.csv\"\n",
    "\n",
    "# Define function for conversion\n",
    "def convert_hgnc_to_zfin(hgnc_ids, output_file=None):\n",
    "    \"\"\"\n",
    "    Converts a list of HGNC IDs (human) to Other Species (e.g. ZFIN IDs (zebrafish)) using Ensembl Biomart.\n",
    "    \n",
    "    Args:\n",
    "        hgnc_ids (list): A list of HGNC IDs to be converted.\n",
    "        output_file (str): Path to save the conversion results (optional).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing input HGNC IDs and their corresponding ZFIN IDs.\n",
    "    \"\"\"\n",
    "    # Biomart server configuration\n",
    "    biomart_server_url = \"http://www.ensembl.org/biomart\"\n",
    "    server = BiomartServer(biomart_server_url)\n",
    "    dataset = server.datasets[dataset_name]\n",
    "\n",
    "    # Query attributes\n",
    "    attributes = [\n",
    "        \"ensembl_gene_id\",  # Ensembl Gene ID\n",
    "        \"hgnc_id\",          # HGNC ID (human)\n",
    "         gene_id_field,      # Species to convert to\n",
    "         gene_symbol_field\n",
    "    ]\n",
    "    \n",
    "    # Build query\n",
    "    response = dataset.search({\n",
    "        \"filters\": {\n",
    "            \"hgnc_id\": hgnc_ids\n",
    "        },\n",
    "        \"attributes\": attributes,\n",
    "    })\n",
    "\n",
    "    # Parse response to DataFrame\n",
    "    results = pd.read_csv(response, sep=\"\\t\", header=None, names=attributes)\n",
    "\n",
    "    # Save results if output_file is provided\n",
    "    if output_file:\n",
    "        results.to_csv(output_file, index=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Call function and print results\n",
    "    result_df = convert_hgnc_to_zfin(hgnc_id, output_filename)\n",
    "    print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b780a12-5d7c-42da-a39b-2619557bd3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to data/llm_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ijson\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Set output file name\n",
    "output_file = \"data/llm_results.csv\"\n",
    "top_n = 8\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Define your custom stop/include words\n",
    "custom_stop_words = [\n",
    "    \"make\", \"significant\", \"activity\", \"made\", \"makes\", \"significantly\",\n",
    "    \"activities\", \"activity\", \"attenuated\", \"induced\", \"enhanced\", \"attenuates\", \n",
    "    \"induces\", \"enhances\", \"available\", \"abstract\", \"rarely\", \"result\", \"results\",\n",
    "    \"produced\", \"produce\", \"important\", \"prominent\", \"role\", \"11\", \"12\", \"10\",\n",
    "    \"18\", \"19\", \"\",\n",
    "]\n",
    "custom_include_keywords = [\n",
    "    \"cancer\", \"tumor\", \"tumour\", \"signaling\", \"signalling\", \"cell communication\", \"protein-coding\",\n",
    "    \"protein coding\", \"non-protein coding\"\n",
    "    \"lncrna\", \"lnc-rna\", \"differentiation\", \"immune response\", \"non-inflammatory\", \"inflammatory\",\n",
    "    \"hypoxia\", \"TME\", \"microenvironment\", \"cell-cell\", \"cell-to-cell\", \"dendritic differentiation\",\n",
    "    \"gene regulation\", \"heterogeneity\", \"growth factor\"\n",
    "]\n",
    "\n",
    "# Combine default English stop words and custom stop words\n",
    "combined_stop_words = list(ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "# Initialize CountVectorizer with the updated stop words\n",
    "vectorizer = CountVectorizer(max_features=top_n, stop_words=combined_stop_words)\n",
    "\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text using the tokenizer.\n",
    "    \"\"\"\n",
    "    return len(tokenizer.encode(text, truncation=False))\n",
    "\n",
    "\n",
    "def chunk_abstracts(abstracts, max_tokens=16000):\n",
    "    \"\"\"\n",
    "    Split the abstracts into chunks based on the maximum token limit.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for abstract in abstracts:\n",
    "        abstract_tokens = count_tokens(abstract)\n",
    "        if current_tokens + abstract_tokens > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [abstract]\n",
    "            current_tokens = abstract_tokens\n",
    "        else:\n",
    "            current_chunk.append(abstract)\n",
    "            current_tokens += abstract_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def extract_keywords(text, top_n=top_n):\n",
    "    \"\"\"\n",
    "    Extract top N keywords (including multi-word keywords) from a text using CountVectorizer.\n",
    "    Exclude combined stop words, ensure inclusion of custom keywords, and filter out numeric keywords.\n",
    "    Handle empty vocabulary errors.\n",
    "    \"\"\"\n",
    "    if not text.strip():\n",
    "        return \"\"  # Return an empty string if the text is empty\n",
    "\n",
    "    try:\n",
    "        # Remove purely numeric words from the text\n",
    "        filtered_text = \" \".join(word for word in text.split() if not re.match(r\"^\\d+$\", word))\n",
    "\n",
    "        # Configure CountVectorizer to include n-grams (e.g., unigrams and bigrams)\n",
    "        vectorizer = CountVectorizer(\n",
    "            max_features=top_n,\n",
    "            stop_words=combined_stop_words,\n",
    "            ngram_range=(1, 5)  # This includes unigrams (single words), bigrams (two words) till 5 words\n",
    "        )\n",
    "\n",
    "        # Fit the vectorizer to the filtered text and extract keywords\n",
    "        X = vectorizer.fit_transform([filtered_text])\n",
    "        keywords = set(vectorizer.get_feature_names_out())\n",
    "\n",
    "        # Check which custom keywords (including multi-word) are present in the original text\n",
    "        found_custom_keywords = [keyword for keyword in custom_include_keywords if keyword in text.lower()]\n",
    "\n",
    "        # Add the found custom keywords to the set of extracted keywords\n",
    "        keywords.update(found_custom_keywords)\n",
    "\n",
    "        return \", \".join(keywords)\n",
    "    except ValueError as e:\n",
    "        # Handle empty vocabulary error\n",
    "        if \"empty vocabulary\" in str(e):\n",
    "            return \"\"  # Return an empty string if no valid tokens remain\n",
    "        raise  # Re-raise other unexpected errors\n",
    "\n",
    "\n",
    "def process_human_lr_pair(human_lr_pair, abstracts):\n",
    "    \"\"\"\n",
    "    Process each ligand-receptor pair and extract relevant biological keywords.\n",
    "    \"\"\"\n",
    "    # Chunk abstracts into smaller parts\n",
    "    chunks = chunk_abstracts(abstracts)\n",
    "    all_keywords = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Extract keywords from each chunk\n",
    "        keywords = extract_keywords(chunk)\n",
    "        all_keywords.append(keywords)\n",
    "\n",
    "    # Combine all the extracted keywords from each chunk\n",
    "    return {\"Human LR Pair\": human_lr_pair, \"Relevance Keywords\": \", \".join(all_keywords)}\n",
    "\n",
    "\n",
    "# Stream JSON and process incrementally\n",
    "with open(\"data_for_llm.json\", \"r\") as f:\n",
    "    parser = ijson.items(f, \"item\")\n",
    "    results = []\n",
    "\n",
    "    for entry in parser:\n",
    "        human_lr_pair = entry[\"Human LR Pair\"]\n",
    "        abstracts = entry[\"Abstracts\"]\n",
    "        result = process_human_lr_pair(human_lr_pair, abstracts)\n",
    "\n",
    "        # Skip entries where keywords are empty or only numerical\n",
    "        if not result[\"Relevance Keywords\"] or result[\"Relevance Keywords\"].replace(\",\", \"\").isdigit():\n",
    "            continue\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "# Write the final results to CSV (overwrite mode)\n",
    "pd.DataFrame(results).to_csv(output_file, mode=\"w\", header=True, index=False)\n",
    "\n",
    "print(f\"Results written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a6c47ef-4860-4634-a0a1-9978558e5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizer Output: Chemokines play diverse roles in inflammatory and non-inflammatory situations via activation of heptahelical G-protein-coupled receptors. Many chemokine receptors can act as cofactors for cellular entry of human immunodeficiency virus (HIV) in vitro. CCR5, a receptor for chemokines MIP-1alpha (LD78alpha),\n",
      "Extracted Entities: [{'entity_group': 'LABEL_1', 'score': np.float32(0.55091596), 'word': 'ch', 'start': 0, 'end': 2}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5798595), 'word': '##emokines play diverse roles in inflammatory and non - inflammatory situations via activation of', 'start': 2, 'end': 95}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55827105), 'word': 'heptahelical g', 'start': 96, 'end': 110}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53384435), 'word': '- protein', 'start': 110, 'end': 118}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5399335), 'word': '- coupled receptors', 'start': 118, 'end': 136}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5658179), 'word': '. many', 'start': 136, 'end': 142}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5528165), 'word': 'chem', 'start': 143, 'end': 147}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54179275), 'word': '##okine receptors can act as cofactors for', 'start': 147, 'end': 187}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52274555), 'word': 'cellular', 'start': 188, 'end': 196}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5545431), 'word': 'entry of human', 'start': 197, 'end': 211}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5351555), 'word': 'im', 'start': 212, 'end': 214}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56035864), 'word': '##muno', 'start': 214, 'end': 218}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5175606), 'word': '##de', 'start': 218, 'end': 220}, {'entity_group': 'LABEL_0', 'score': np.float32(0.59346896), 'word': '##ficiency virus ( hiv ) in', 'start': 220, 'end': 243}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5005441), 'word': 'v', 'start': 244, 'end': 245}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55594563), 'word': '##itro.', 'start': 245, 'end': 250}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5463952), 'word': 'ccr5', 'start': 251, 'end': 255}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5457313), 'word': ',', 'start': 255, 'end': 256}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5410491), 'word': 'a receptor for chem', 'start': 257, 'end': 276}, {'entity_group': 'LABEL_0', 'score': np.float32(0.550827), 'word': '##okines mip -', 'start': 276, 'end': 287}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5921889), 'word': '1alpha', 'start': 287, 'end': 293}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53663594), 'word': '(', 'start': 294, 'end': 295}, {'entity_group': 'LABEL_1', 'score': np.float32(0.58140475), 'word': 'ld78alpha )', 'start': 295, 'end': 305}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5272836), 'word': ',', 'start': 305, 'end': 306}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['non-inflammatory', 'chemokine', 'in vitro', 'inflammatory', 'chemokines']\n",
      "Summarizer Output: Dichotomy that is not entirely understood. DEFB103 significantly (p < 0.05) enhanced 6 responses, attenuated 7 responses, and both enhanced/attenuated the CXCL1 and TNF responses to Porphyromonas gingivalis hemagglutinin B (HagB) In murine JAWSII dendritic cells\n",
      "Extracted Entities: [{'entity_group': 'LABEL_1', 'score': np.float32(0.5534352), 'word': 'dicho', 'start': 0, 'end': 5}, {'entity_group': 'LABEL_0', 'score': np.float32(0.59309095), 'word': '##tomy that is not entirely understood. defb', 'start': 5, 'end': 47}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5060422), 'word': '##10', 'start': 47, 'end': 49}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57257867), 'word': '##3 significantly (', 'start': 49, 'end': 66}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5037554), 'word': 'p', 'start': 66, 'end': 67}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60378164), 'word': '< 0. 05 ) enhanced 6 responses,', 'start': 68, 'end': 97}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6450873), 'word': 'at', 'start': 98, 'end': 100}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5873094), 'word': '##tenuated', 'start': 100, 'end': 108}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51283246), 'word': '7', 'start': 109, 'end': 110}, {'entity_group': 'LABEL_0', 'score': np.float32(0.61704904), 'word': 'responses, and', 'start': 111, 'end': 125}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51649076), 'word': 'both', 'start': 126, 'end': 130}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60550666), 'word': 'enhanced /', 'start': 131, 'end': 140}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6696108), 'word': 'at', 'start': 140, 'end': 142}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57695967), 'word': '##tenuated the', 'start': 142, 'end': 154}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5466966), 'word': 'cxcl', 'start': 155, 'end': 159}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5244657), 'word': '##1 and', 'start': 159, 'end': 164}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5853426), 'word': 't', 'start': 165, 'end': 166}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6076745), 'word': '##nf responses to porphyromonas gingivalis', 'start': 166, 'end': 206}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5329417), 'word': 'hemag', 'start': 207, 'end': 212}, {'entity_group': 'LABEL_0', 'score': np.float32(0.63299483), 'word': '##g', 'start': 212, 'end': 213}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5170837), 'word': '##lut', 'start': 213, 'end': 216}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60366), 'word': '##inin b ( ha', 'start': 216, 'end': 226}, {'entity_group': 'LABEL_1', 'score': np.float32(0.573983), 'word': '##g', 'start': 226, 'end': 227}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58355886), 'word': '##b ) in', 'start': 227, 'end': 232}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52006674), 'word': 'm', 'start': 233, 'end': 234}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5702783), 'word': '##urine', 'start': 234, 'end': 239}, {'entity_group': 'LABEL_1', 'score': np.float32(0.509269), 'word': 'jaws', 'start': 240, 'end': 244}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5109447), 'word': '##ii', 'start': 244, 'end': 246}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5781145), 'word': 'dendr', 'start': 247, 'end': 252}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6351412), 'word': '##itic', 'start': 252, 'end': 256}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5268059), 'word': 'cells', 'start': 257, 'end': 262}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for DEFB103B——CCR2\n",
      "Summarizer Output: There was no significant difference in eliciting Ca(2+) flux and chemotaxis among the variants with the exception of LD78beta(T9A) showing a substantially reduced activity. The order for CCR5 down-regulation induction was comparable to that for binding inhibition. Pro-2, Asp-6, Pro-8, and Thr-9 are critical for LD\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.54919153), 'word': 'there was no significant difference in', 'start': 0, 'end': 38}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5391335), 'word': 'el', 'start': 39, 'end': 41}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5966725), 'word': '##iciting ca ( 2 + ) flux and', 'start': 41, 'end': 64}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5496987), 'word': 'ch', 'start': 65, 'end': 67}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55723774), 'word': '##emotaxis among', 'start': 67, 'end': 81}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50029397), 'word': 'the', 'start': 82, 'end': 85}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5762759), 'word': 'variants with the exception of', 'start': 86, 'end': 116}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5614523), 'word': 'ld78beta ( t9a', 'start': 117, 'end': 129}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5589703), 'word': ') showing a substantially', 'start': 129, 'end': 154}, {'entity_group': 'LABEL_1', 'score': np.float32(0.530402), 'word': 'reduced activity', 'start': 155, 'end': 171}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55239856), 'word': '. the order for', 'start': 171, 'end': 186}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55857897), 'word': 'ccr5 down - regulation', 'start': 187, 'end': 207}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5721693), 'word': 'induction was comparable to that for binding', 'start': 208, 'end': 252}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5465279), 'word': 'in', 'start': 253, 'end': 255}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5779669), 'word': '##hibition. pro - 2,', 'start': 255, 'end': 271}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5362518), 'word': 'as', 'start': 272, 'end': 274}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5690002), 'word': '##p - 6, pro -', 'start': 274, 'end': 283}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5485561), 'word': '8', 'start': 283, 'end': 284}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6560733), 'word': ', and', 'start': 284, 'end': 289}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56053114), 'word': 'thr', 'start': 290, 'end': 293}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5737558), 'word': '-', 'start': 293, 'end': 294}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52404535), 'word': '9', 'start': 294, 'end': 295}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5725986), 'word': 'are critical', 'start': 296, 'end': 308}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5360353), 'word': 'for l', 'start': 309, 'end': 314}, {'entity_group': 'LABEL_0', 'score': np.float32(0.52823263), 'word': '##d', 'start': 314, 'end': 315}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for CCL3L3——CCR5\n",
      "Summarizer Output: Dichotomy that is not entirely understood. DEFB103 significantly (p < 0.05) enhanced 6 responses, attenuated 7 responses, and both enhanced/attenuated the CXCL1 and TNF responses to Porphyromonas gingivalis hemagglutinin B (HagB) In murine JAWSII dendritic cells\n",
      "Extracted Entities: [{'entity_group': 'LABEL_1', 'score': np.float32(0.5534352), 'word': 'dicho', 'start': 0, 'end': 5}, {'entity_group': 'LABEL_0', 'score': np.float32(0.59309095), 'word': '##tomy that is not entirely understood. defb', 'start': 5, 'end': 47}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5060422), 'word': '##10', 'start': 47, 'end': 49}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57257867), 'word': '##3 significantly (', 'start': 49, 'end': 66}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5037554), 'word': 'p', 'start': 66, 'end': 67}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60378164), 'word': '< 0. 05 ) enhanced 6 responses,', 'start': 68, 'end': 97}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6450873), 'word': 'at', 'start': 98, 'end': 100}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5873094), 'word': '##tenuated', 'start': 100, 'end': 108}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51283246), 'word': '7', 'start': 109, 'end': 110}, {'entity_group': 'LABEL_0', 'score': np.float32(0.61704904), 'word': 'responses, and', 'start': 111, 'end': 125}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51649076), 'word': 'both', 'start': 126, 'end': 130}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60550666), 'word': 'enhanced /', 'start': 131, 'end': 140}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6696108), 'word': 'at', 'start': 140, 'end': 142}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57695967), 'word': '##tenuated the', 'start': 142, 'end': 154}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5466966), 'word': 'cxcl', 'start': 155, 'end': 159}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5244657), 'word': '##1 and', 'start': 159, 'end': 164}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5853426), 'word': 't', 'start': 165, 'end': 166}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6076745), 'word': '##nf responses to porphyromonas gingivalis', 'start': 166, 'end': 206}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5329417), 'word': 'hemag', 'start': 207, 'end': 212}, {'entity_group': 'LABEL_0', 'score': np.float32(0.63299483), 'word': '##g', 'start': 212, 'end': 213}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5170837), 'word': '##lut', 'start': 213, 'end': 216}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60366), 'word': '##inin b ( ha', 'start': 216, 'end': 226}, {'entity_group': 'LABEL_1', 'score': np.float32(0.573983), 'word': '##g', 'start': 226, 'end': 227}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58355886), 'word': '##b ) in', 'start': 227, 'end': 232}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52006674), 'word': 'm', 'start': 233, 'end': 234}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5702783), 'word': '##urine', 'start': 234, 'end': 239}, {'entity_group': 'LABEL_1', 'score': np.float32(0.509269), 'word': 'jaws', 'start': 240, 'end': 244}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5109447), 'word': '##ii', 'start': 244, 'end': 246}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5781145), 'word': 'dendr', 'start': 247, 'end': 252}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6351412), 'word': '##itic', 'start': 252, 'end': 256}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5268059), 'word': 'cells', 'start': 257, 'end': 262}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for DEFB103B——CCR6\n",
      "Summarizer Output: Defensins contribute to host defense by disrupting the cytoplasmic membrane of microorganisms. This report shows that human beta-defensins are also chemotactic for immature dendritic cells and memory T cells. The binding of iodinated LARC to CCR6-transfected cells was competitively displaced by beta- defensin.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.5704042), 'word': 'defensins contribute to host defense by disrupting the cytoplasmic', 'start': 0, 'end': 66}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5133846), 'word': 'membrane', 'start': 67, 'end': 75}, {'entity_group': 'LABEL_0', 'score': np.float32(0.59152746), 'word': 'of microorganisms. this report shows that human beta', 'start': 76, 'end': 128}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5334465), 'word': '-', 'start': 128, 'end': 129}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55101323), 'word': 'defensins are also', 'start': 129, 'end': 147}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5775359), 'word': 'ch', 'start': 148, 'end': 150}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5408932), 'word': '##emota', 'start': 150, 'end': 155}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5334447), 'word': '##ctic', 'start': 155, 'end': 159}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5128552), 'word': 'for', 'start': 160, 'end': 163}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55610543), 'word': 'im', 'start': 164, 'end': 166}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5489183), 'word': '##mature den', 'start': 166, 'end': 176}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5368133), 'word': '##dr', 'start': 176, 'end': 178}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6589134), 'word': '##itic', 'start': 178, 'end': 182}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5059335), 'word': 'cells', 'start': 183, 'end': 188}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57441354), 'word': 'and memory t cells. the binding of', 'start': 189, 'end': 223}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5758352), 'word': 'iod', 'start': 224, 'end': 227}, {'entity_group': 'LABEL_0', 'score': np.float32(0.7097057), 'word': '##inated', 'start': 227, 'end': 233}, {'entity_group': 'LABEL_1', 'score': np.float32(0.543889), 'word': 'la', 'start': 234, 'end': 236}, {'entity_group': 'LABEL_0', 'score': np.float32(0.555874), 'word': '##rc to', 'start': 236, 'end': 241}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5758868), 'word': 'ccr', 'start': 242, 'end': 245}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5088513), 'word': '##6 -', 'start': 245, 'end': 247}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5198529), 'word': 'trans', 'start': 247, 'end': 252}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5528684), 'word': '##fected cells was competitively displaced by', 'start': 252, 'end': 295}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53308964), 'word': 'beta -', 'start': 296, 'end': 301}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5379098), 'word': 'def', 'start': 302, 'end': 305}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5059826), 'word': '##ens', 'start': 305, 'end': 308}, {'entity_group': 'LABEL_0', 'score': np.float32(0.61806226), 'word': '##in', 'start': 308, 'end': 310}, {'entity_group': 'LABEL_1', 'score': np.float32(0.512396), 'word': '.', 'start': 310, 'end': 311}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for DEFB4A——CCR6\n",
      "Summarizer Output: Vertebrates have multiple genes encoding Type I interferons (IFN), for reasons that are not fully understood. The Type I IFN appear to bind to the same heterodimeric receptor and the subtypes have been shown to have different potencies.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_1', 'score': np.float32(0.52429324), 'word': 'vertebra', 'start': 0, 'end': 8}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50149953), 'word': '##tes have', 'start': 8, 'end': 16}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5051551), 'word': 'multiple', 'start': 17, 'end': 25}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5557871), 'word': 'genes encoding', 'start': 26, 'end': 40}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5538101), 'word': 'type i interfer', 'start': 41, 'end': 56}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53965265), 'word': '##ons (', 'start': 56, 'end': 61}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57411253), 'word': 'ifn', 'start': 61, 'end': 64}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5678588), 'word': '), for reasons that', 'start': 64, 'end': 83}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5512699), 'word': 'are not', 'start': 84, 'end': 91}, {'entity_group': 'LABEL_0', 'score': np.float32(0.550199), 'word': 'fully understood. the', 'start': 92, 'end': 113}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55343264), 'word': 'type i ifn', 'start': 114, 'end': 124}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5909724), 'word': 'appear', 'start': 125, 'end': 131}, {'entity_group': 'LABEL_1', 'score': np.float32(0.59695464), 'word': 'to bind to the same heterodimeric receptor', 'start': 132, 'end': 174}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5876779), 'word': 'and', 'start': 175, 'end': 178}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57686615), 'word': 'the subtypes', 'start': 179, 'end': 191}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5629354), 'word': 'have been shown to have different potencies.', 'start': 192, 'end': 236}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['interferons']\n",
      "Summarizer Output: Vertebrates have multiple genes encoding Type I interferons (IFN), for reasons that are not fully understood. The Type I IFN appear to bind to the same heterodimeric receptor and the subtypes have been shown to have different potencies.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_1', 'score': np.float32(0.52429324), 'word': 'vertebra', 'start': 0, 'end': 8}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50149953), 'word': '##tes have', 'start': 8, 'end': 16}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5051551), 'word': 'multiple', 'start': 17, 'end': 25}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5557871), 'word': 'genes encoding', 'start': 26, 'end': 40}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5538101), 'word': 'type i interfer', 'start': 41, 'end': 56}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53965265), 'word': '##ons (', 'start': 56, 'end': 61}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57411253), 'word': 'ifn', 'start': 61, 'end': 64}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5678588), 'word': '), for reasons that', 'start': 64, 'end': 83}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5512699), 'word': 'are not', 'start': 84, 'end': 91}, {'entity_group': 'LABEL_0', 'score': np.float32(0.550199), 'word': 'fully understood. the', 'start': 92, 'end': 113}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55343264), 'word': 'type i ifn', 'start': 114, 'end': 124}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5909724), 'word': 'appear', 'start': 125, 'end': 131}, {'entity_group': 'LABEL_1', 'score': np.float32(0.59695464), 'word': 'to bind to the same heterodimeric receptor', 'start': 132, 'end': 174}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5876779), 'word': 'and', 'start': 175, 'end': 178}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57686615), 'word': 'the subtypes', 'start': 179, 'end': 191}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5629354), 'word': 'have been shown to have different potencies.', 'start': 192, 'end': 236}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['interferons']\n",
      "Summarizer Output: IL-17A and IL-17F, produced by the Th17 CD4(+) T cell lineage, have been linked to a variety of inflammatory and autoimmune conditions. All three cytokines can induce chemokine secretion from bronchial epithelial cells, albeit with different potencies.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.559039), 'word': 'il - 17a and il - 17', 'start': 0, 'end': 16}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53514296), 'word': '##f', 'start': 16, 'end': 17}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5991473), 'word': ', produced', 'start': 17, 'end': 27}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5542679), 'word': 'by the th17 cd4 ( + ) t cell', 'start': 28, 'end': 53}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58646977), 'word': 'lineage, have been linked to a variety of inflammatory and autoimmune conditions. all three', 'start': 54, 'end': 145}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5064187), 'word': 'c', 'start': 146, 'end': 147}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56711197), 'word': '##ytokines can', 'start': 147, 'end': 159}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5491119), 'word': 'induce ch', 'start': 160, 'end': 169}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58948475), 'word': '##emokine', 'start': 169, 'end': 176}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5054919), 'word': 'secret', 'start': 177, 'end': 183}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55862236), 'word': '##ion from bronchia', 'start': 183, 'end': 200}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5350663), 'word': '##l e', 'start': 200, 'end': 203}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57959193), 'word': '##pithelial cells, albeit with different potencies.', 'start': 203, 'end': 252}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['immune', 'cytokine', 'chemokine', 'inflammatory']\n",
      "Summarizer Output: The epithelial-mesenchymal interactions required for kidney organogenesis are disrupted in mice lacking the integrin alpha8beta1. None of this integrin's known ligands, however, appears to account for this phenotype.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.5666903), 'word': 'the epithelial', 'start': 0, 'end': 14}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5002213), 'word': '-', 'start': 14, 'end': 15}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5039791), 'word': 'me', 'start': 15, 'end': 17}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52805054), 'word': '##sen', 'start': 17, 'end': 20}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54674476), 'word': '##chy', 'start': 20, 'end': 23}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55391926), 'word': '##mal', 'start': 23, 'end': 26}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57146144), 'word': 'interactions required for kidney organogenesis are disrupted in mice lacking the', 'start': 27, 'end': 107}, {'entity_group': 'LABEL_1', 'score': np.float32(0.54860604), 'word': 'inte', 'start': 108, 'end': 112}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53574777), 'word': '##g', 'start': 112, 'end': 113}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53013575), 'word': '##rin alpha8bet', 'start': 113, 'end': 126}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57101285), 'word': '##a', 'start': 126, 'end': 127}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5170633), 'word': '##1.', 'start': 127, 'end': 129}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5616946), 'word': 'none of this', 'start': 130, 'end': 142}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5415357), 'word': 'inte', 'start': 143, 'end': 147}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50358003), 'word': '##g', 'start': 147, 'end': 148}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51923853), 'word': '##rin', 'start': 148, 'end': 151}, {'entity_group': 'LABEL_0', 'score': np.float32(0.67712206), 'word': \"'\", 'start': 151, 'end': 152}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5344503), 'word': 's', 'start': 152, 'end': 153}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56367683), 'word': 'known', 'start': 154, 'end': 159}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5653014), 'word': 'l', 'start': 160, 'end': 161}, {'entity_group': 'LABEL_0', 'score': np.float32(0.60579413), 'word': '##igands, however, appears to', 'start': 161, 'end': 188}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5304236), 'word': 'account', 'start': 189, 'end': 196}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5649716), 'word': 'for this phenotype', 'start': 197, 'end': 215}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5335274), 'word': '.', 'start': 215, 'end': 216}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['mice']\n",
      "Summarizer Output: The LH receptor (LHR) mediates the actions of LH and human chorionic gonadotropin (hCG) In vitro data showed that deletion of exon 10 does not affect hCG action, whereas LH action is impaired.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.5351916), 'word': 'the', 'start': 0, 'end': 3}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5241675), 'word': 'l', 'start': 4, 'end': 5}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54313123), 'word': '##h receptor (', 'start': 5, 'end': 17}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5398108), 'word': 'lhr', 'start': 17, 'end': 20}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57057637), 'word': ') mediates the actions of', 'start': 20, 'end': 45}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5215782), 'word': 'l', 'start': 46, 'end': 47}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5434487), 'word': '##h and', 'start': 47, 'end': 52}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56831205), 'word': 'human chorionic go', 'start': 53, 'end': 71}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5292058), 'word': '##nado', 'start': 71, 'end': 75}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5135202), 'word': '##tro', 'start': 75, 'end': 78}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6208708), 'word': '##pin (', 'start': 78, 'end': 83}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5946963), 'word': 'hc', 'start': 83, 'end': 85}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57395434), 'word': '##g ) in', 'start': 85, 'end': 90}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50536436), 'word': 'v', 'start': 91, 'end': 92}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5443626), 'word': '##it', 'start': 92, 'end': 94}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5035749), 'word': '##ro', 'start': 94, 'end': 96}, {'entity_group': 'LABEL_0', 'score': np.float32(0.590006), 'word': 'data showed that deletion of exon 10 does not affect', 'start': 97, 'end': 149}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5525396), 'word': 'hc', 'start': 150, 'end': 152}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5725791), 'word': '##g action, whereas lh action is impaired.', 'start': 152, 'end': 192}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['in vitro']\n",
      "Summarizer Output: Studies on human LH receptors are difficult due to the limited availability of clinical samples. Recent cloning of rat and porcine LH receptor cDNAs indicated that these binding sites are single polypeptides of the G-protein-coupled receptor family with seven transmembrane domains. The present work should provide the basis for future design of therapeutic agents.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.5691275), 'word': 'studies', 'start': 0, 'end': 7}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53285265), 'word': 'on human lh', 'start': 8, 'end': 19}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54357284), 'word': 'receptors are difficult due to', 'start': 20, 'end': 50}, {'entity_group': 'LABEL_1', 'score': np.float32(0.504617), 'word': 'the', 'start': 51, 'end': 54}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55996525), 'word': 'limited', 'start': 55, 'end': 62}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53392446), 'word': 'availability', 'start': 63, 'end': 75}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5572708), 'word': 'of clinical samples. recent', 'start': 76, 'end': 103}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5414921), 'word': 'clon', 'start': 104, 'end': 108}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5604658), 'word': '##ing of', 'start': 108, 'end': 114}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57859486), 'word': 'rat', 'start': 115, 'end': 118}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50782084), 'word': 'and', 'start': 119, 'end': 122}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5136232), 'word': 'p', 'start': 123, 'end': 124}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5654361), 'word': '##orcine', 'start': 124, 'end': 130}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5610591), 'word': 'lh', 'start': 131, 'end': 133}, {'entity_group': 'LABEL_0', 'score': np.float32(0.507994), 'word': 'receptor', 'start': 134, 'end': 142}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5769069), 'word': 'cdn', 'start': 143, 'end': 146}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5732098), 'word': '##as indicated that these binding sites', 'start': 146, 'end': 183}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56676036), 'word': 'are single poly', 'start': 184, 'end': 199}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50461113), 'word': '##pe', 'start': 199, 'end': 201}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5178094), 'word': '##ptides of the g', 'start': 201, 'end': 216}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53345346), 'word': '- protein -', 'start': 216, 'end': 225}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5578122), 'word': 'coupled receptor', 'start': 225, 'end': 241}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5521939), 'word': 'family with', 'start': 242, 'end': 253}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53301364), 'word': 'seven transme', 'start': 254, 'end': 267}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5068349), 'word': '##mb', 'start': 267, 'end': 269}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55521226), 'word': '##rane', 'start': 269, 'end': 273}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5769271), 'word': 'domains.', 'start': 274, 'end': 282}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5209247), 'word': 'the', 'start': 283, 'end': 286}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55089116), 'word': 'present work', 'start': 287, 'end': 299}, {'entity_group': 'LABEL_1', 'score': np.float32(0.54663295), 'word': 'should provide the basis', 'start': 300, 'end': 324}, {'entity_group': 'LABEL_0', 'score': np.float32(0.524328), 'word': 'for future', 'start': 325, 'end': 335}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52003765), 'word': 'design', 'start': 336, 'end': 342}, {'entity_group': 'LABEL_0', 'score': np.float32(0.528045), 'word': 'of', 'start': 343, 'end': 345}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5195888), 'word': 'therapeutic', 'start': 346, 'end': 357}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5132546), 'word': 'agents', 'start': 358, 'end': 364}, {'entity_group': 'LABEL_1', 'score': np.float32(0.60010606), 'word': '.', 'start': 364, 'end': 365}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "Summarizer Output: COOH termini of synaptotagmins 1, 2, 4, 5, 6, 7, and 9 and rabphilin 3A are capable of interacting with neurexins. The conservation between carboxyl termins of these proteins suggests symmetrical motifs are necessary for Neurexin binding.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.609589), 'word': 'cooh', 'start': 0, 'end': 4}, {'entity_group': 'LABEL_1', 'score': np.float32(0.60572755), 'word': 'term', 'start': 5, 'end': 9}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57332766), 'word': '##ini of', 'start': 9, 'end': 15}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5591756), 'word': 'synapt', 'start': 16, 'end': 22}, {'entity_group': 'LABEL_0', 'score': np.float32(0.51057947), 'word': '##ota', 'start': 22, 'end': 25}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53604954), 'word': '##g', 'start': 25, 'end': 26}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5706043), 'word': '##mins', 'start': 26, 'end': 30}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52182055), 'word': '1,', 'start': 31, 'end': 33}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5471834), 'word': '2', 'start': 34, 'end': 35}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5268039), 'word': ',', 'start': 35, 'end': 36}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5084232), 'word': '4', 'start': 37, 'end': 38}, {'entity_group': 'LABEL_1', 'score': np.float32(0.517262), 'word': ',', 'start': 38, 'end': 39}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5372143), 'word': '5, 6,', 'start': 40, 'end': 45}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51527274), 'word': '7', 'start': 46, 'end': 47}, {'entity_group': 'LABEL_0', 'score': np.float32(0.61820126), 'word': ',', 'start': 47, 'end': 48}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5355895), 'word': 'and 9', 'start': 49, 'end': 54}, {'entity_group': 'LABEL_0', 'score': np.float32(0.533718), 'word': 'and', 'start': 55, 'end': 58}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55137604), 'word': 'r', 'start': 59, 'end': 60}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56469613), 'word': '##abphilin 3a are capable of interacting with', 'start': 60, 'end': 103}, {'entity_group': 'LABEL_1', 'score': np.float32(0.61916685), 'word': 'neure', 'start': 104, 'end': 109}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57312983), 'word': '##xins. the conservation between carbox', 'start': 109, 'end': 146}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5977825), 'word': '##yl term', 'start': 146, 'end': 153}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5740134), 'word': '##ins of these proteins suggests symmetrical motifs are necessary for', 'start': 153, 'end': 220}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6187751), 'word': 'neure', 'start': 221, 'end': 226}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57441294), 'word': '##xin binding', 'start': 226, 'end': 237}, {'entity_group': 'LABEL_1', 'score': np.float32(0.574955), 'word': '.', 'start': 237, 'end': 238}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for RPH3A——NRXN1\n",
      "Summarizer Output: Previously we showed that the low-molecular-weight mucin (MG2, encoded by MUC7), a major component of human submandibular/sublingual saliva, is a bacterial receptor. Here we tested the hypothesis that the structure of its carbohydrate residues contains important information about its function.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.6578505), 'word': 'previously we showed that the', 'start': 0, 'end': 29}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57647574), 'word': 'low', 'start': 30, 'end': 33}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5785851), 'word': '- molecular -', 'start': 33, 'end': 44}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5927243), 'word': 'weight', 'start': 44, 'end': 50}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58773124), 'word': 'mucin ( mg2, encoded', 'start': 51, 'end': 70}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5095841), 'word': 'by', 'start': 71, 'end': 73}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6048073), 'word': 'muc7 ), a major component of human submandibular / sublingual saliva, is a bacterial receptor. here we tested the hypothesis that the', 'start': 74, 'end': 204}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5333277), 'word': 'structure', 'start': 205, 'end': 214}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5904902), 'word': 'of its', 'start': 215, 'end': 221}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6099088), 'word': 'car', 'start': 222, 'end': 225}, {'entity_group': 'LABEL_0', 'score': np.float32(0.51031053), 'word': '##bo', 'start': 225, 'end': 227}, {'entity_group': 'LABEL_1', 'score': np.float32(0.58828324), 'word': '##hydrate', 'start': 227, 'end': 234}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5981162), 'word': 'residues contains important information about its function.', 'start': 235, 'end': 294}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for MUC7——SELL\n",
      "Summarizer Output: MDF2beta acts directly on immature dendritic cells as an endogenous ligand for Toll-like receptor 4 (TLR-4) It induces up-regulation of costimulatory molecules and d endritic cell maturation. These events trigger robust, type 1 polarized adaptive immune responses in vivo.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_1', 'score': np.float32(0.509513), 'word': 'm', 'start': 0, 'end': 1}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5291434), 'word': '##d', 'start': 1, 'end': 2}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5255509), 'word': '##f2bet', 'start': 2, 'end': 7}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5689907), 'word': '##a acts directly', 'start': 7, 'end': 22}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5941459), 'word': 'on im', 'start': 23, 'end': 28}, {'entity_group': 'LABEL_0', 'score': np.float32(0.52462226), 'word': '##mat', 'start': 28, 'end': 31}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5571211), 'word': '##ure dendr', 'start': 31, 'end': 40}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5563931), 'word': '##itic', 'start': 40, 'end': 44}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5098348), 'word': 'cells', 'start': 45, 'end': 50}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57684785), 'word': 'as an endogenous', 'start': 51, 'end': 67}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6025308), 'word': 'l', 'start': 68, 'end': 69}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5771976), 'word': '##igand for toll -', 'start': 69, 'end': 84}, {'entity_group': 'LABEL_1', 'score': np.float32(0.55898947), 'word': 'like receptor 4', 'start': 84, 'end': 99}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56487054), 'word': '(', 'start': 100, 'end': 101}, {'entity_group': 'LABEL_1', 'score': np.float32(0.60359967), 'word': 'tlr - 4', 'start': 101, 'end': 106}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5527084), 'word': ') it induces up - regulation of costimulatory molecules and d endritic cell', 'start': 106, 'end': 179}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5247463), 'word': 'mat', 'start': 180, 'end': 183}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5546697), 'word': '##uration. these events', 'start': 183, 'end': 204}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5150572), 'word': 'trigger', 'start': 205, 'end': 212}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5470475), 'word': 'robust,', 'start': 213, 'end': 220}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5711791), 'word': 'type 1 polar', 'start': 221, 'end': 233}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58809286), 'word': '##ized', 'start': 233, 'end': 237}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5128754), 'word': 'adaptive immune responses', 'start': 238, 'end': 263}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54672694), 'word': 'in vivo', 'start': 264, 'end': 271}, {'entity_group': 'LABEL_1', 'score': np.float32(0.54593426), 'word': '.', 'start': 271, 'end': 272}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['immune', 'in vivo']\n",
      "Summarizer Output: IL-27 is an early product of activated antigen-presenting cells. It drives rapid clonal expansion of naive but not memory CD4(+) T cells. IL-27 mediates its biologic effects through the orphan cytokine receptor WSX-1/TCCR.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.56887513), 'word': 'il - 27 is an', 'start': 0, 'end': 11}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50185055), 'word': 'early', 'start': 12, 'end': 17}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5689816), 'word': 'product of activated antigen - presenting cells. it drives rapid c', 'start': 18, 'end': 82}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53640807), 'word': '##lon', 'start': 82, 'end': 85}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57326496), 'word': '##al expansion of naive but', 'start': 85, 'end': 110}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50472325), 'word': 'not', 'start': 111, 'end': 114}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5491955), 'word': 'memory', 'start': 115, 'end': 121}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57102084), 'word': 'cd', 'start': 122, 'end': 124}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50687367), 'word': '##4', 'start': 124, 'end': 125}, {'entity_group': 'LABEL_1', 'score': np.float32(0.576938), 'word': '( + ) t', 'start': 125, 'end': 130}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5698284), 'word': 'cells. il - 27 mediates its biologic effects through the orphan', 'start': 131, 'end': 192}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50954473), 'word': 'c', 'start': 193, 'end': 194}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58095443), 'word': '##ytokine receptor ws', 'start': 194, 'end': 213}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53293735), 'word': '##x - 1', 'start': 213, 'end': 216}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56013376), 'word': '/', 'start': 216, 'end': 217}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57080287), 'word': 't', 'start': 217, 'end': 218}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5224901), 'word': '##ccr.', 'start': 218, 'end': 222}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['cytokine']\n",
      "Summarizer Output: Human interleukin 17 (hIL-17) is a T-cell derived cytokine that exhibits 63% amino acid sequence identity to mouse IL-17 (mIL- 17) and 57% identity to a viral protein encoded by the herpesvirus saimiri (HSV) gene 13 (HVS13) The IL- 17 family of proteins binds to\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.54677206), 'word': 'human', 'start': 0, 'end': 5}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56712705), 'word': 'interle', 'start': 6, 'end': 13}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5509006), 'word': '##ukin', 'start': 13, 'end': 17}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5164796), 'word': '17', 'start': 18, 'end': 20}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54524535), 'word': '( hi', 'start': 21, 'end': 24}, {'entity_group': 'LABEL_1', 'score': np.float32(0.59796566), 'word': '##l', 'start': 24, 'end': 25}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5069893), 'word': '-', 'start': 25, 'end': 26}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5223792), 'word': '17', 'start': 26, 'end': 28}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5857319), 'word': ') is a', 'start': 28, 'end': 34}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50586754), 'word': 't -', 'start': 35, 'end': 37}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5636592), 'word': 'cell', 'start': 37, 'end': 41}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5173384), 'word': 'derived c', 'start': 42, 'end': 51}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5932434), 'word': '##ytokine that exhibits 63 % amino', 'start': 51, 'end': 82}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51264286), 'word': 'acid', 'start': 83, 'end': 87}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5416131), 'word': 'sequence identity to mouse', 'start': 88, 'end': 114}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51775163), 'word': 'il - 17', 'start': 115, 'end': 120}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5593786), 'word': '( mi', 'start': 121, 'end': 124}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5495002), 'word': '##l - 17', 'start': 124, 'end': 129}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58394694), 'word': ') and', 'start': 129, 'end': 134}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51044714), 'word': '57', 'start': 135, 'end': 137}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5389725), 'word': '% identity to a', 'start': 137, 'end': 152}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5011321), 'word': 'viral', 'start': 153, 'end': 158}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5797433), 'word': 'protein encoded by the', 'start': 159, 'end': 181}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50262755), 'word': 'her', 'start': 182, 'end': 185}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57628495), 'word': '##pesvirus saimiri (', 'start': 185, 'end': 203}, {'entity_group': 'LABEL_1', 'score': np.float32(0.6109173), 'word': 'h', 'start': 203, 'end': 204}, {'entity_group': 'LABEL_0', 'score': np.float32(0.566851), 'word': '##sv ) gene', 'start': 204, 'end': 212}, {'entity_group': 'LABEL_1', 'score': np.float32(0.54933614), 'word': '13', 'start': 213, 'end': 215}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5312991), 'word': '(', 'start': 216, 'end': 217}, {'entity_group': 'LABEL_1', 'score': np.float32(0.59303397), 'word': 'h', 'start': 217, 'end': 218}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56923527), 'word': '##v', 'start': 218, 'end': 219}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5617765), 'word': '##s13', 'start': 219, 'end': 222}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5338134), 'word': ')', 'start': 222, 'end': 223}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50719994), 'word': 'the', 'start': 224, 'end': 227}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5707241), 'word': 'il - 17 family of proteins binds to', 'start': 228, 'end': 262}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['interleukin', 'cytokine', 'mouse']\n",
      "Summarizer Output: IL-17A and IL-17F, produced by the Th17 CD4(+) T cell lineage, have been linked to a variety of inflammatory and autoimmune conditions. All three cytokines can induce chemokine secretion from bronchial epithelial cells, albeit with different potencies.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.559039), 'word': 'il - 17a and il - 17', 'start': 0, 'end': 16}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53514296), 'word': '##f', 'start': 16, 'end': 17}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5991473), 'word': ', produced', 'start': 17, 'end': 27}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5542679), 'word': 'by the th17 cd4 ( + ) t cell', 'start': 28, 'end': 53}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58646977), 'word': 'lineage, have been linked to a variety of inflammatory and autoimmune conditions. all three', 'start': 54, 'end': 145}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5064187), 'word': 'c', 'start': 146, 'end': 147}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56711197), 'word': '##ytokines can', 'start': 147, 'end': 159}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5491119), 'word': 'induce ch', 'start': 160, 'end': 169}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58948475), 'word': '##emokine', 'start': 169, 'end': 176}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5054919), 'word': 'secret', 'start': 177, 'end': 183}, {'entity_group': 'LABEL_0', 'score': np.float32(0.55862236), 'word': '##ion from bronchia', 'start': 183, 'end': 200}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5350663), 'word': '##l e', 'start': 200, 'end': 203}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57959193), 'word': '##pithelial cells, albeit with different potencies.', 'start': 203, 'end': 252}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['immune', 'cytokine', 'chemokine', 'inflammatory']\n",
      "Summarizer Output: IL-27 is an early product of activated antigen-presenting cells. It drives rapid clonal expansion of naive but not memory CD4(+) T cells. IL-27 mediates its biologic effects through the orphan cytokine receptor WSX-1/TCCR.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.56887513), 'word': 'il - 27 is an', 'start': 0, 'end': 11}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50185055), 'word': 'early', 'start': 12, 'end': 17}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5689816), 'word': 'product of activated antigen - presenting cells. it drives rapid c', 'start': 18, 'end': 82}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53640807), 'word': '##lon', 'start': 82, 'end': 85}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57326496), 'word': '##al expansion of naive but', 'start': 85, 'end': 110}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50472325), 'word': 'not', 'start': 111, 'end': 114}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5491955), 'word': 'memory', 'start': 115, 'end': 121}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57102084), 'word': 'cd', 'start': 122, 'end': 124}, {'entity_group': 'LABEL_0', 'score': np.float32(0.50687367), 'word': '##4', 'start': 124, 'end': 125}, {'entity_group': 'LABEL_1', 'score': np.float32(0.576938), 'word': '( + ) t', 'start': 125, 'end': 130}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5698284), 'word': 'cells. il - 27 mediates its biologic effects through the orphan', 'start': 131, 'end': 192}, {'entity_group': 'LABEL_1', 'score': np.float32(0.50954473), 'word': 'c', 'start': 193, 'end': 194}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58095443), 'word': '##ytokine receptor ws', 'start': 194, 'end': 213}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53293735), 'word': '##x - 1', 'start': 213, 'end': 216}, {'entity_group': 'LABEL_0', 'score': np.float32(0.56013376), 'word': '/', 'start': 216, 'end': 217}, {'entity_group': 'LABEL_1', 'score': np.float32(0.57080287), 'word': 't', 'start': 217, 'end': 218}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5224901), 'word': '##ccr.', 'start': 218, 'end': 222}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['cytokine']\n",
      "Summarizer Output: Type XIII collagen consists of a short N-terminal intracellular domain, a transmembrane domain, and a collagenous ectodomain. It is found at many sites of cell adhesion. The binding sites of type XIII collagen for fibronectin were localized to the collagenous domains.\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.5683007), 'word': 'type xiii collagen consists of a short n - terminal intracellular domain,', 'start': 0, 'end': 71}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51818544), 'word': 'a', 'start': 72, 'end': 73}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54119295), 'word': 'trans', 'start': 74, 'end': 79}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5358711), 'word': '##me', 'start': 79, 'end': 81}, {'entity_group': 'LABEL_0', 'score': np.float32(0.58083725), 'word': '##mbrane domain, and a collagenous', 'start': 81, 'end': 113}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5901306), 'word': 'e', 'start': 114, 'end': 115}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57371396), 'word': '##ctodomain. it is found at many sites of cell adhesion. the binding sites of type', 'start': 115, 'end': 195}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5098352), 'word': 'x', 'start': 196, 'end': 197}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5336416), 'word': '##iii', 'start': 197, 'end': 200}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5207702), 'word': 'co', 'start': 201, 'end': 203}, {'entity_group': 'LABEL_0', 'score': np.float32(0.572534), 'word': '##llagen for fibronectin were localized', 'start': 203, 'end': 240}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5289247), 'word': 'to', 'start': 241, 'end': 243}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5572604), 'word': 'the collagenous domains', 'start': 244, 'end': 267}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5038679), 'word': '.', 'start': 267, 'end': 268}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: []\n",
      "No relevant entities found for NID2——COL13A1\n",
      "Summarizer Output: The epithelial-mesenchymal interactions required for kidney organogenesis are disrupted in mice lacking the integrin alpha8beta1. None of this integrin's known ligands, however, appears to account for this phenotype. In newborn mouse kidney extracts, alpha8 beta1-AP detects a novel ligand of 70-90 kD. This protein, named nephron\n",
      "Extracted Entities: [{'entity_group': 'LABEL_0', 'score': np.float32(0.544906), 'word': 'the', 'start': 0, 'end': 3}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5072641), 'word': 'e', 'start': 4, 'end': 5}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5820078), 'word': '##pithelial', 'start': 5, 'end': 14}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52546364), 'word': '- mesen', 'start': 14, 'end': 20}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5405069), 'word': '##chy', 'start': 20, 'end': 23}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5671684), 'word': '##mal', 'start': 23, 'end': 26}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5713303), 'word': 'interactions required for kidney organogenesis are disrupted in mice lacking the', 'start': 27, 'end': 107}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56157476), 'word': 'inte', 'start': 108, 'end': 112}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5509014), 'word': '##g', 'start': 112, 'end': 113}, {'entity_group': 'LABEL_1', 'score': np.float32(0.53405523), 'word': '##rin alpha8bet', 'start': 113, 'end': 126}, {'entity_group': 'LABEL_0', 'score': np.float32(0.53533363), 'word': '##a', 'start': 126, 'end': 127}, {'entity_group': 'LABEL_1', 'score': np.float32(0.52156943), 'word': '##1', 'start': 127, 'end': 128}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5557557), 'word': '. none of this', 'start': 128, 'end': 142}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5527375), 'word': 'inte', 'start': 143, 'end': 147}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5292849), 'word': '##g', 'start': 147, 'end': 148}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5249045), 'word': '##rin', 'start': 148, 'end': 151}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6864285), 'word': \"'\", 'start': 151, 'end': 152}, {'entity_group': 'LABEL_1', 'score': np.float32(0.54251003), 'word': 's', 'start': 152, 'end': 153}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5739887), 'word': 'known', 'start': 154, 'end': 159}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56091017), 'word': 'l', 'start': 160, 'end': 161}, {'entity_group': 'LABEL_0', 'score': np.float32(0.6147394), 'word': '##igands, however, appears to', 'start': 161, 'end': 188}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5266277), 'word': 'account', 'start': 189, 'end': 196}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5583193), 'word': 'for this phenotype. in', 'start': 197, 'end': 219}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5049367), 'word': 'newborn', 'start': 220, 'end': 227}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5374796), 'word': 'mouse', 'start': 228, 'end': 233}, {'entity_group': 'LABEL_1', 'score': np.float32(0.51210153), 'word': 'kidney', 'start': 234, 'end': 240}, {'entity_group': 'LABEL_0', 'score': np.float32(0.59002906), 'word': 'extracts,', 'start': 241, 'end': 250}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5668929), 'word': 'alpha8 beta1 - a', 'start': 251, 'end': 265}, {'entity_group': 'LABEL_0', 'score': np.float32(0.5460404), 'word': '##p detects a novel', 'start': 265, 'end': 282}, {'entity_group': 'LABEL_1', 'score': np.float32(0.62979436), 'word': 'l', 'start': 283, 'end': 284}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54362863), 'word': '##igand of 70', 'start': 284, 'end': 295}, {'entity_group': 'LABEL_1', 'score': np.float32(0.56582797), 'word': '-', 'start': 295, 'end': 296}, {'entity_group': 'LABEL_0', 'score': np.float32(0.52774996), 'word': '90', 'start': 296, 'end': 298}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5943512), 'word': 'k', 'start': 299, 'end': 300}, {'entity_group': 'LABEL_0', 'score': np.float32(0.57872784), 'word': '##d. this protein, named', 'start': 300, 'end': 322}, {'entity_group': 'LABEL_1', 'score': np.float32(0.5210897), 'word': 'ne', 'start': 323, 'end': 325}, {'entity_group': 'LABEL_0', 'score': np.float32(0.54817307), 'word': '##phron', 'start': 325, 'end': 330}]\n",
      "No BioBERT entities found. Using fallback mechanism.\n",
      "Fallback Keywords: ['mice', 'mouse']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m human_lr_pair \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman LR Pair\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    133\u001b[0m abstracts \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstracts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 134\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_human_lr_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman_lr_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstracts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Write results incrementally to CSV to save memory\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 123\u001b[0m, in \u001b[0;36mprocess_human_lr_pair\u001b[0;34m(human_lr_pair, abstracts, tokenizer)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_human_lr_pair\u001b[39m(human_lr_pair, abstracts, tokenizer):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Process a single ligand-receptor pair.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     relevance \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_relevance_hf_with_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstracts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_lr_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman LR Pair\u001b[39m\u001b[38;5;124m\"\u001b[39m: human_lr_pair, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance Keywords\u001b[39m\u001b[38;5;124m\"\u001b[39m: relevance}\n",
      "Cell \u001b[0;32mIn[42], line 104\u001b[0m, in \u001b[0;36manalyze_relevance_hf_with_chunks\u001b[0;34m(abstracts, human_lr_pair, tokenizer, max_tokens)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m     99\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPubMed Abstracts:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize the biological relevance of the interaction between the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mligand-receptor pair: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhuman_lr_pair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     )\n\u001b[0;32m--> 104\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     summary_text \u001b[38;5;241m=\u001b[39m summary[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Log summarizer output for debugging\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:274\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:167\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m    172\u001b[0m     ):\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/pipelines/base.py:1301\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         )\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/pipelines/base.py:1308\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1307\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1308\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1309\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/pipelines/base.py:1208\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1207\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1208\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:196\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    194\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 196\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/generation/utils.py:2283\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2275\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2276\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2277\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2278\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2280\u001b[0m     )\n\u001b[1;32m   2282\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2283\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2295\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2296\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2297\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2303\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2304\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/generation/utils.py:3503\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3500\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_text_config())\n\u001b[1;32m   3502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 3503\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3506\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3507\u001b[0m     outputs,\n\u001b[1;32m   3508\u001b[0m     model_kwargs,\n\u001b[1;32m   3509\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3510\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1642\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1638\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1639\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1640\u001b[0m         )\n\u001b[0;32m-> 1642\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1660\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1661\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1528\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1521\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1522\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1523\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1524\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1525\u001b[0m     )\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1528\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1380\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1368\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1369\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         use_cache,\n\u001b[1;32m   1378\u001b[0m     )\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:695\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    694\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m--> 695\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_attn_layer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;66;03m# add cross-attn to positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    698\u001b[0m present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/modules/normalization.py:217\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/quarto_llm_env/lib/python3.11/site-packages/torch/nn/functional.py:2900\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2892\u001b[0m         layer_norm,\n\u001b[1;32m   2893\u001b[0m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2898\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2899\u001b[0m     )\n\u001b[0;32m-> 2900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ijson\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "\n",
    "# Load BioBERT for NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
    "\n",
    "# Load summarizer\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)  # Use GPU if available\n",
    "\n",
    "output_file = \"data/bio_filtered_llm_results.csv\"\n",
    "\n",
    "def count_tokens(text, tokenizer):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in the text.\n",
    "    \"\"\"\n",
    "    return len(tokenizer.encode(text, truncation=False))\n",
    "\n",
    "def chunk_abstracts(abstracts, tokenizer, max_tokens=16000):\n",
    "    \"\"\"\n",
    "    Split abstracts into chunks without exceeding the token limit.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for abstract in abstracts:\n",
    "        abstract_tokens = count_tokens(abstract, tokenizer)\n",
    "        if current_tokens + abstract_tokens > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [abstract]\n",
    "            current_tokens = abstract_tokens\n",
    "        else:\n",
    "            current_chunk.append(abstract)\n",
    "            current_tokens += abstract_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Predefined keywords for fallback mechanism\n",
    "RELEVANT_KEYWORDS = {\n",
    "    \"cancer\", \"tumor\", \"pathway\", \"inflammation\", \"inflammatory\", \"protein coding\", \"protein-coding\",\n",
    "    \"mouse\", \"mice\", \"zebrafish\", \"non-inflammatory\", \"HIV infection\", \"cytokine\", \"TME\", \"interferons\",\n",
    "    \"apoptosis\", \"disease\", \"signaling\",\"signalling\", \"metastasis\", \"microenvironment\",\n",
    "    \"lncrna\", \"cell-cell\", \"cell to cell\", \"cell-to-cell\", \"cell communication\",\n",
    "    \"disease\", \"disorder\", \"lncrna\", \"gene regulation\", \"growth factor\", \n",
    "    \"chemokine\", \"chemokines\", \"cell cycle\", \"proliferation\", \"immunoresponse\", \"immune\", \"toxicity\", \n",
    "    \"differentiation\", \"stem cell\", \"abnormalities\", \"in vitro\", \"in vivo\", \"in-vitro\", \"in-vivo\",\n",
    "    \"heterogeneity\", \"hypoxia\", \"interleukin\", \"lnc-rna\", \"infection\",\n",
    "}\n",
    "\n",
    "def extract_keywords_fallback(text):\n",
    "    \"\"\"\n",
    "    Fallback to extract relevant keywords from the text.\n",
    "    \"\"\"\n",
    "    found_keywords = [word for word in RELEVANT_KEYWORDS if word in text.lower()]\n",
    "    print(\"Fallback Keywords:\", found_keywords)  # Debugging\n",
    "    return found_keywords\n",
    "\n",
    "def extract_relevant_entities(summary):\n",
    "    \"\"\"\n",
    "    Use BioBERT to extract relevant entities from the summary.\n",
    "    If no entities are found, fallback to predefined keywords.\n",
    "    \"\"\"\n",
    "    entities = ner_pipeline(summary)\n",
    "    \n",
    "    # Log all extracted entities for debugging\n",
    "    print(\"Extracted Entities:\", entities)\n",
    "    \n",
    "    # Filter entities by group\n",
    "    relevant_entities = [\n",
    "        entity[\"word\"] for entity in entities\n",
    "        if entity[\"entity_group\"] in {\"DISEASE\", \"PATHWAY\", \"GENE\", \"PROCESS\"}\n",
    "    ]\n",
    "    \n",
    "    if not relevant_entities:\n",
    "        # No entities found by BioBERT, use fallback\n",
    "        print(\"No BioBERT entities found. Using fallback mechanism.\")\n",
    "        relevant_entities = extract_keywords_fallback(summary)\n",
    "    \n",
    "    # Deduplicate and return results\n",
    "    return list(set(relevant_entities))\n",
    "\n",
    "def analyze_relevance_hf_with_chunks(abstracts, human_lr_pair, tokenizer, max_tokens=1024):\n",
    "    \"\"\"\n",
    "    Analyze biological relevance by summarizing abstracts and extracting entities.\n",
    "    Adds a fallback mechanism for keyword-based filtering.\n",
    "    \"\"\"\n",
    "    chunks = chunk_abstracts(abstracts, tokenizer, max_tokens=max_tokens)\n",
    "    filtered_entities = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        input_text = (\n",
    "            f\"PubMed Abstracts:\\n{chunk}\\n\\n\"\n",
    "            f\"Summarize the biological relevance of the interaction between the \"\n",
    "            f\"ligand-receptor pair: {human_lr_pair}.\"\n",
    "        )\n",
    "        summary = summarizer(input_text, max_length=80, min_length=20, do_sample=False)\n",
    "        summary_text = summary[0][\"summary_text\"]\n",
    "        \n",
    "        # Log summarizer output for debugging\n",
    "        print(\"Summarizer Output:\", summary_text)\n",
    "        \n",
    "        # Extract entities using BioBERT (with fallback)\n",
    "        entities = extract_relevant_entities(summary_text)\n",
    "        filtered_entities.extend(entities)\n",
    "\n",
    "    if not filtered_entities:\n",
    "        print(f\"No relevant entities found for {human_lr_pair}\")\n",
    "\n",
    "    return \", \".join(set(filtered_entities))  # Combine and deduplicate\n",
    "\n",
    "def process_human_lr_pair(human_lr_pair, abstracts, tokenizer):\n",
    "    \"\"\"\n",
    "    Process a single ligand-receptor pair.\n",
    "    \"\"\"\n",
    "    relevance = analyze_relevance_hf_with_chunks(abstracts, human_lr_pair, tokenizer)\n",
    "    return {\"Human LR Pair\": human_lr_pair, \"Relevance Keywords\": relevance}\n",
    "\n",
    "# Stream JSON and process incrementally\n",
    "with open(\"data_for_llm.json\", \"r\") as f:\n",
    "    parser = ijson.items(f, \"item\")\n",
    "    results = []\n",
    "\n",
    "    for entry in parser:\n",
    "        human_lr_pair = entry[\"Human LR Pair\"]\n",
    "        abstracts = entry[\"Abstracts\"]\n",
    "        result = process_human_lr_pair(human_lr_pair, abstracts, tokenizer)\n",
    "        results.append(result)\n",
    "\n",
    "        # Write results incrementally to CSV to save memory\n",
    "        pd.DataFrame([result]).to_csv(output_file, mode='a', header=not bool(results), index=False)\n",
    "\n",
    "print(f\"Filtered results written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "336b2cb2-5f71-46fa-816a-e8effa7aca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Human LR Pair</th>\n",
       "      <th>PMID support</th>\n",
       "      <th>Relevance Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCL3L3——ACKR2</td>\n",
       "      <td>10364178,</td>\n",
       "      <td>mip, 1alphap, ccr5, non-inflammatory, mip 1alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEFB103B——CCR2</td>\n",
       "      <td>23390582,</td>\n",
       "      <td>dendritic, dendritic cells defb103, cells defb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCL3L3——CCR5</td>\n",
       "      <td>11734558,10364178,</td>\n",
       "      <td>human, 1alphap, ld78beta, ccr5, binding, mip, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEFB103B——CCR6</td>\n",
       "      <td>23390582,</td>\n",
       "      <td>dendritic, dendritic cells defb103, cells defb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEFB4A——CCR6</td>\n",
       "      <td>10521347,11714836,</td>\n",
       "      <td>chemokine, dendritic, immature, immune respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>KIR2DL5A——PVR</td>\n",
       "      <td>36377656,</td>\n",
       "      <td>cancer, human, shp, kir2dl5 pvr, signaling, ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>SAA1——SCARB1</td>\n",
       "      <td>15561721,</td>\n",
       "      <td>bi, saa, lipid, hdl, uptake, sr bi, selective, sr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>SAA1——TLR2</td>\n",
       "      <td>18566366,</td>\n",
       "      <td>saa, tlr2, activation, expression, inflammator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>SAA1——TLR4</td>\n",
       "      <td>35247611,</td>\n",
       "      <td>phase response protein obesity, response, nafl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>SAA3P——LY96</td>\n",
       "      <td>23858030,</td>\n",
       "      <td>saa3 20 86, tlr4, tlr4 md, md, 20, 86, 20 86, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2373 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Human LR Pair        PMID support  \\\n",
       "0      CCL3L3——ACKR2           10364178,   \n",
       "1     DEFB103B——CCR2           23390582,   \n",
       "2       CCL3L3——CCR5  11734558,10364178,   \n",
       "3     DEFB103B——CCR6           23390582,   \n",
       "4       DEFB4A——CCR6  10521347,11714836,   \n",
       "...              ...                 ...   \n",
       "2368   KIR2DL5A——PVR           36377656,   \n",
       "2369    SAA1——SCARB1           15561721,   \n",
       "2370      SAA1——TLR2           18566366,   \n",
       "2371      SAA1——TLR4           35247611,   \n",
       "2372     SAA3P——LY96           23858030,   \n",
       "\n",
       "                                     Relevance Keywords  \n",
       "0     mip, 1alphap, ccr5, non-inflammatory, mip 1alp...  \n",
       "1     dendritic, dendritic cells defb103, cells defb...  \n",
       "2     human, 1alphap, ld78beta, ccr5, binding, mip, ...  \n",
       "3     dendritic, dendritic cells defb103, cells defb...  \n",
       "4     chemokine, dendritic, immature, immune respons...  \n",
       "...                                                 ...  \n",
       "2368  cancer, human, shp, kir2dl5 pvr, signaling, ki...  \n",
       "2369  bi, saa, lipid, hdl, uptake, sr bi, selective, sr  \n",
       "2370  saa, tlr2, activation, expression, inflammator...  \n",
       "2371  phase response protein obesity, response, nafl...  \n",
       "2372  saa3 20 86, tlr4, tlr4 md, md, 20, 86, 20 86, ...  \n",
       "\n",
       "[2373 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function to create an evidence page per Human LR Pair with each tab per PMID\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "TEMPLATE_PATH = \"HTML/pmidTemplate.html\"\n",
    "OUTPUT_DIR = \"data/pubmed/\"\n",
    "\n",
    "# Add the src directory to the path for importing modules\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "from createDataTable import gene_pair00\n",
    "\n",
    "# Load PubMed data\n",
    "pubmed_data = pd.read_csv(\"data/pubmed_results.csv\")\n",
    "pubmed_data[\"Year\"] = pubmed_data[\"Year\"].astype(str).str.replace(\".0\", \n",
    "                                                                  \"\", \n",
    "                                                                  regex=False).astype(int)\n",
    "\n",
    "pubmed_data[\"PMID\"] = pubmed_data[\"PMID\"].astype(str)\n",
    "\n",
    "# add llm results\n",
    "bio_keywords = pd.read_csv(\"data/llm_results.csv\")\n",
    "\n",
    "\n",
    "# Replace spaces in \"Human LR Pair\" with a placeholder\n",
    "gene_pair00[\"Human LR Pair\"] = gene_pair00[\"Human LR Pair\"].str.replace(\" \", \"——\")\n",
    "\n",
    "gene_pair000 = gene_pair00.merge(bio_keywords, how='left', left_on=\"Human LR Pair\", right_on='Human LR Pair')\n",
    "gene_pair000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ede08395-0e6e-453a-94ba-f06ca1d3d312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Human LR Pair', 'PMID support', 'Relevance Keywords'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_pair000.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69297bc8-4599-4340-bc84-b1542327c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        CCL3L3——ACKR2\n",
       "1       DEFB103B——CCR2\n",
       "2         CCL3L3——CCR5\n",
       "3       DEFB103B——CCR6\n",
       "4         DEFB4A——CCR6\n",
       "             ...      \n",
       "2368     KIR2DL5A——PVR\n",
       "2369      SAA1——SCARB1\n",
       "2370        SAA1——TLR2\n",
       "2371        SAA1——TLR4\n",
       "2372       SAA3P——LY96\n",
       "Name: Human LR Pair, Length: 2373, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_pair000[\"Human LR Pair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e856a491-a1db-4217-a545-c5ae737f685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        CCL3L3——ACKR2\n",
       "1       DEFB103B——CCR2\n",
       "2         CCL3L3——CCR5\n",
       "3       DEFB103B——CCR6\n",
       "4         DEFB4A——CCR6\n",
       "             ...      \n",
       "2368     KIR2DL5A——PVR\n",
       "2369      SAA1——SCARB1\n",
       "2370        SAA1——TLR2\n",
       "2371        SAA1——TLR4\n",
       "2372       SAA3P——LY96\n",
       "Name: Human LR Pair, Length: 2373, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_pair000[\"Human LR Pair\"]  = gene_pair000[\"Human LR Pair\"].astype(str)\n",
    "gene_pair000[\"Human LR Pair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fa76a-8446-43d6-993d-898aea4e882d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quarto_llm_env",
   "language": "python",
   "name": "quarto_llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
