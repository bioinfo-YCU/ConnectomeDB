{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc5ddc1-519e-439c-a130-3dd8bcd181bd",
   "metadata": {},
   "source": [
    "# Python Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a784e-b5c6-45cc-913b-105533b74457",
   "metadata": {},
   "outputs": [],
   "source": [
    "        // Check for image load completion\n",
    "        var imagePromises = Array.from(images).map(function (img) {\n",
    "            return new Promise(function (resolve, reject) {\n",
    "                if (img.complete) {\n",
    "                    resolve(); // If already loaded\n",
    "                } else {\n",
    "                    img.onload = resolve; // Resolve promise when image is loaded\n",
    "                    img.onerror = reject; // Reject promise if image fails to load\n",
    "                }\n",
    "            });\n",
    "        });\n",
    "    \n",
    "        // Wait for all images to load before generating the PDF\n",
    "        Promise.all(imagePromises)\n",
    "            .then(function () {\n",
    "                console.log(\"All images loaded successfully.\");\n",
    "                downloadPDF();\n",
    "            })\n",
    "            .catch(function (error) {\n",
    "                console.error(\"Image loading error:\", error);\n",
    "                downloadPDF(); // Proceed even if there's an error\n",
    "            });\n",
    "    };\n",
    "    // uncomment until here if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443872e-66e7-427a-a031-75a16471e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(change):\n",
    "    global gene_pair\n",
    "    # Add a new row at the top with None values\n",
    "    new_row = {col: None for col in gene_pair.columns}\n",
    "    gene_pair = pd.DataFrame([new_row] + gene_pair.to_dict(orient=\"records\"))\n",
    "    update_table()\n",
    "\n",
    "# Function to remove the last row of the dataframe\n",
    "def remove_row(change):\n",
    "    global gene_pair\n",
    "    if len(gene_pair) > 0:\n",
    "        gene_pair = gene_pair[:-1]  # Remove the last row\n",
    "        update_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f917d-b5b9-409e-bc04-7b95afd9a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pair.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19161b56-8989-458f-80ef-d1e3eb97e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = gene_pair00[gene_pair00[\"Human LR Pair\"].duplicated()]\n",
    "print(duplicates[\"Human LR Pair\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d79fce-3cfa-469a-abdb-cd05c49d221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create horizontal bar plots of each gene in Human Taxon --expression log(x+1) transformed with cell types as y-axis\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sys.path.append(os.path.abspath(\"src\"))  # Add src directory to path\n",
    "from createDataTable import gene_pair0\n",
    "\n",
    "# Input file\n",
    "input_file=\"data/connectome_j.tsv\" #\"data/connectome_j.tsv\" # data/ExpressionGenes.txt\n",
    "# Get all unique genes\n",
    "ligand_list = gene_pair0[\"Ligand\"].tolist()\n",
    "receptor_list = gene_pair0[\"Receptor\"].tolist()\n",
    "unique_genes = list(set(ligand_list + receptor_list))  # Combine and remove duplicates\n",
    "\n",
    "connectomeDB = pd.read_table(input_file, sep=\"\\t\")\n",
    "# All Taxon for now\n",
    "#connectomeDB = connectomeDB[connectomeDB[\"Taxon\"]== \"Human\"]\n",
    "if \"Taxon\" in connectomeDB.columns:\n",
    "    connectomeDB = connectomeDB.drop(columns=[\"Localization\", \"Taxon\"] + [col for col in connectomeDB.columns if col.startswith(\"F5_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5564ed-51a3-4f4b-8dc0-57f7a31358e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sums = connectomeDB.iloc[:, 1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b32bc0-ebe0-4f37-ac0b-ac81d07ccae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adipocyte Breast           819735.859\n",
       "Adipocyte Omental          883713.058\n",
       "Adipocyte Perirenal        944323.351\n",
       "Adipocyte Subcutaneous     805931.943\n",
       "Alveolar Epithelial       1212346.313\n",
       "                             ...     \n",
       "Synoviocyte                769408.174\n",
       "Tenocyte                   818224.667\n",
       "Trabecular Meshwork       1048484.198\n",
       "Tracheal Epithelial       1224157.145\n",
       "Urothelial                 782699.893\n",
       "Length: 144, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectomeDB.iloc[:, 1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c62af8-646e-4a62-8f19-adfc56766c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApprovedSymbol</th>\n",
       "      <th>Adipocyte Breast</th>\n",
       "      <th>Adipocyte Omental</th>\n",
       "      <th>Adipocyte Perirenal</th>\n",
       "      <th>Adipocyte Subcutaneous</th>\n",
       "      <th>Alveolar Epithelial</th>\n",
       "      <th>Amniotic Epithelial</th>\n",
       "      <th>Amniotic Membrane</th>\n",
       "      <th>Annulus Pulposus</th>\n",
       "      <th>Astrocyte Cerebellum</th>\n",
       "      <th>...</th>\n",
       "      <th>Smooth Muscle Subclavian Artery</th>\n",
       "      <th>Smooth Muscle Tracheal</th>\n",
       "      <th>Smooth Muscle Umbilical Artery</th>\n",
       "      <th>Smooth Muscle Umbilical Vein</th>\n",
       "      <th>Smooth Muscle Uterine</th>\n",
       "      <th>Synoviocyte</th>\n",
       "      <th>Tenocyte</th>\n",
       "      <th>Trabecular Meshwork</th>\n",
       "      <th>Tracheal Epithelial</th>\n",
       "      <th>Urothelial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2M</td>\n",
       "      <td>90.272</td>\n",
       "      <td>121.423</td>\n",
       "      <td>50.596</td>\n",
       "      <td>63.397</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>37.598</td>\n",
       "      <td>2.324</td>\n",
       "      <td>0.143</td>\n",
       "      <td>3.193</td>\n",
       "      <td>2.208</td>\n",
       "      <td>5.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AANAT</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ABCA1</td>\n",
       "      <td>35.775</td>\n",
       "      <td>39.428</td>\n",
       "      <td>15.702</td>\n",
       "      <td>53.803</td>\n",
       "      <td>4.630</td>\n",
       "      <td>4.476</td>\n",
       "      <td>15.274</td>\n",
       "      <td>13.863</td>\n",
       "      <td>7.470</td>\n",
       "      <td>...</td>\n",
       "      <td>48.214</td>\n",
       "      <td>8.643</td>\n",
       "      <td>24.584</td>\n",
       "      <td>22.316</td>\n",
       "      <td>26.252</td>\n",
       "      <td>12.729</td>\n",
       "      <td>16.151</td>\n",
       "      <td>7.366</td>\n",
       "      <td>16.106</td>\n",
       "      <td>26.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>ACE</td>\n",
       "      <td>0.973</td>\n",
       "      <td>1.616</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.308</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513</td>\n",
       "      <td>4.649</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.336</td>\n",
       "      <td>1.419</td>\n",
       "      <td>28.083</td>\n",
       "      <td>17.078</td>\n",
       "      <td>1.634</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ACKR2</td>\n",
       "      <td>22.320</td>\n",
       "      <td>18.048</td>\n",
       "      <td>20.064</td>\n",
       "      <td>2.658</td>\n",
       "      <td>12.704</td>\n",
       "      <td>43.018</td>\n",
       "      <td>89.229</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.258</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.511</td>\n",
       "      <td>7.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16424</th>\n",
       "      <td>XCR1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16470</th>\n",
       "      <td>YBX1</td>\n",
       "      <td>58.803</td>\n",
       "      <td>54.388</td>\n",
       "      <td>58.447</td>\n",
       "      <td>73.160</td>\n",
       "      <td>76.354</td>\n",
       "      <td>80.877</td>\n",
       "      <td>43.623</td>\n",
       "      <td>85.979</td>\n",
       "      <td>113.238</td>\n",
       "      <td>...</td>\n",
       "      <td>67.607</td>\n",
       "      <td>104.832</td>\n",
       "      <td>91.272</td>\n",
       "      <td>102.638</td>\n",
       "      <td>51.795</td>\n",
       "      <td>57.435</td>\n",
       "      <td>74.201</td>\n",
       "      <td>106.607</td>\n",
       "      <td>67.368</td>\n",
       "      <td>69.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16676</th>\n",
       "      <td>ZG16B</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.828</td>\n",
       "      <td>6.106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.146</td>\n",
       "      <td>...</td>\n",
       "      <td>5.168</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.987</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.419</td>\n",
       "      <td>1.233</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.655</td>\n",
       "      <td>10.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17213</th>\n",
       "      <td>ZNRF3</td>\n",
       "      <td>2.787</td>\n",
       "      <td>4.775</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.944</td>\n",
       "      <td>8.512</td>\n",
       "      <td>4.954</td>\n",
       "      <td>6.021</td>\n",
       "      <td>2.709</td>\n",
       "      <td>8.275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.799</td>\n",
       "      <td>3.743</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.564</td>\n",
       "      <td>1.774</td>\n",
       "      <td>4.336</td>\n",
       "      <td>3.029</td>\n",
       "      <td>8.329</td>\n",
       "      <td>5.204</td>\n",
       "      <td>5.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17217</th>\n",
       "      <td>ZP3</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.564</td>\n",
       "      <td>1.745</td>\n",
       "      <td>1.824</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.723</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.826</td>\n",
       "      <td>1.209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.890</td>\n",
       "      <td>1.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.081</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.729</td>\n",
       "      <td>8.676</td>\n",
       "      <td>7.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1316 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ApprovedSymbol  Adipocyte Breast  Adipocyte Omental  \\\n",
       "2                A2M            90.272            121.423   \n",
       "16             AANAT             0.000              0.000   \n",
       "28             ABCA1            35.775             39.428   \n",
       "133              ACE             0.973              1.616   \n",
       "140            ACKR2            22.320             18.048   \n",
       "...              ...               ...                ...   \n",
       "16424           XCR1             0.000              0.000   \n",
       "16470           YBX1            58.803             54.388   \n",
       "16676          ZG16B             0.091              0.828   \n",
       "17213          ZNRF3             2.787              4.775   \n",
       "17217            ZP3             0.701              0.564   \n",
       "\n",
       "       Adipocyte Perirenal  Adipocyte Subcutaneous  Alveolar Epithelial  \\\n",
       "2                   50.596                  63.397                0.000   \n",
       "16                   0.000                   0.000                0.000   \n",
       "28                  15.702                  53.803                4.630   \n",
       "133                  0.000                   2.308                0.000   \n",
       "140                 20.064                   2.658               12.704   \n",
       "...                    ...                     ...                  ...   \n",
       "16424                0.000                   0.000                0.000   \n",
       "16470               58.447                  73.160               76.354   \n",
       "16676                6.106                   0.000                0.698   \n",
       "17213                0.872                   0.944                8.512   \n",
       "17217                1.745                   1.824                0.595   \n",
       "\n",
       "       Amniotic Epithelial  Amniotic Membrane  Annulus Pulposus  \\\n",
       "2                    0.000              0.819             0.000   \n",
       "16                   0.000              0.000             0.000   \n",
       "28                   4.476             15.274            13.863   \n",
       "133                  0.132              0.819             0.765   \n",
       "140                 43.018             89.229             0.537   \n",
       "...                    ...                ...               ...   \n",
       "16424                0.000              0.656             0.000   \n",
       "16470               80.877             43.623            85.979   \n",
       "16676                0.218              0.000             0.579   \n",
       "17213                4.954              6.021             2.709   \n",
       "17217                0.723              1.117             0.826   \n",
       "\n",
       "       Astrocyte Cerebellum  ...  Smooth Muscle Subclavian Artery  \\\n",
       "2                     1.364  ...                            0.146   \n",
       "16                    0.000  ...                            0.000   \n",
       "28                    7.470  ...                           48.214   \n",
       "133                   0.878  ...                            0.513   \n",
       "140                   0.987  ...                            0.368   \n",
       "...                     ...  ...                              ...   \n",
       "16424                 0.000  ...                            0.000   \n",
       "16470               113.238  ...                           67.607   \n",
       "16676                 0.146  ...                            5.168   \n",
       "17213                 8.275  ...                            1.799   \n",
       "17217                 1.209  ...                            0.844   \n",
       "\n",
       "       Smooth Muscle Tracheal  Smooth Muscle Umbilical Artery  \\\n",
       "2                      37.598                           2.324   \n",
       "16                      0.000                           0.000   \n",
       "28                      8.643                          24.584   \n",
       "133                     4.649                           0.606   \n",
       "140                     0.868                           0.179   \n",
       "...                       ...                             ...   \n",
       "16424                   0.000                           0.000   \n",
       "16470                 104.832                          91.272   \n",
       "16676                   0.000                           1.987   \n",
       "17213                   3.743                           2.169   \n",
       "17217                   0.579                           0.890   \n",
       "\n",
       "       Smooth Muscle Umbilical Vein  Smooth Muscle Uterine  Synoviocyte  \\\n",
       "2                             0.143                  3.193        2.208   \n",
       "16                            0.000                  0.000        0.000   \n",
       "28                           22.316                 26.252       12.729   \n",
       "133                           0.336                  1.419       28.083   \n",
       "140                           0.313                  0.000        1.258   \n",
       "...                             ...                    ...          ...   \n",
       "16424                         0.000                  0.000        0.000   \n",
       "16470                       102.638                 51.795       57.435   \n",
       "16676                         0.000                  1.419        1.233   \n",
       "17213                         2.564                  1.774        4.336   \n",
       "17217                         1.337                  0.000        1.081   \n",
       "\n",
       "       Tenocyte  Trabecular Meshwork  Tracheal Epithelial  Urothelial  \n",
       "2         5.266                0.000                0.223       0.000  \n",
       "16        0.000                0.000                0.000       0.000  \n",
       "28       16.151                7.366               16.106      26.339  \n",
       "133      17.078                1.634                0.447       0.115  \n",
       "140       0.875                0.000                0.511       7.038  \n",
       "...         ...                  ...                  ...         ...  \n",
       "16424     0.000                0.000                0.000       0.000  \n",
       "16470    74.201              106.607               67.368      69.804  \n",
       "16676     0.442                0.190                1.655      10.423  \n",
       "17213     3.029                8.329                5.204       5.714  \n",
       "17217     0.760                0.729                8.676       7.013  \n",
       "\n",
       "[1316 rows x 145 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection = pd.Series(list(set(connectomeDB['ApprovedSymbol']).intersection(unique_genes)))\n",
    "intersection\n",
    "\n",
    "connectomeDB = connectomeDB[connectomeDB[\"ApprovedSymbol\"].isin(intersection)]\n",
    "connectomeDB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7707cc4d-426a-41a1-8f1a-fe68ffb62330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(x+1) transform\n",
    "connectomeDB.iloc[:, 1:] = np.log1p(connectomeDB.iloc[:, 1:])\n",
    "# Reshape \n",
    "connectomeDB_long = connectomeDB.melt(id_vars=[\"ApprovedSymbol\"], \n",
    "                                      var_name=\"cellTypes\", value_name=\"expr_val\")\n",
    "cellCat = pd.read_csv(\"data/cell_categories.csv\")\n",
    "connectomeDB_long = connectomeDB_long.merge(cellCat, how='left', left_on='cellTypes', right_on='cellType')\n",
    "connectomeDB_long = connectomeDB_long.drop(columns=[\"cellType\"])\n",
    "\n",
    "intersection = pd.Series(list(set(connectomeDB_long['cellTypes']).intersection(set(cellCat['cellType']))))\n",
    "intersection\n",
    "\n",
    "diff_df = pd.Series(list(set(connectomeDB_long['cellTypes']).difference(set(cellCat['cellType']))))\n",
    "diff_df\n",
    "\n",
    "def plot_gene_expression(df):\n",
    "    # Define the colors for each cell category\n",
    "    colors = {\n",
    "        \"missing\": \"#B0B0B0\",  # Neutral gray\n",
    "        \"other\": \"#D4A76A\",  # Warm gold\n",
    "        \"mesenchymal\": \"#377EB8\",  # Vibrant blue\n",
    "        \"epithelial\": \"#E41A1C\",  # Bold red\n",
    "        \"hematopoietic\": \"#4DAF4A\",  # Fresh green\n",
    "        \"endothelial\": \"#984EA3\",  # Deep purple\n",
    "        \"nervous system\": \"#FF7F00\",  # Bright orange\n",
    "    }\n",
    "\n",
    "    # Define sorting order for cell categories\n",
    "    category_order = {cat: i for i, cat in enumerate(colors.keys())}\n",
    "\n",
    "    for gene, sub_df in df.groupby(\"ApprovedSymbol\"):\n",
    "        # Sort by category first, then by expression value (highest first)\n",
    "        sub_df = sub_df.copy()\n",
    "        sub_df[\"category_order\"] = sub_df[\"cellCategory\"].map(category_order).fillna(len(category_order))\n",
    "        sub_df = sub_df.sort_values([\"category_order\", \"expr_val\"], ascending=[True, False])\n",
    "\n",
    "        num_bars = len(sub_df)\n",
    "\n",
    "        # Plotly Figure setup\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Loop through each category and create a trace for it\n",
    "        for category, color in colors.items():\n",
    "            # Filter data for the current category\n",
    "            category_data = sub_df[sub_df[\"cellCategory\"] == category]\n",
    "\n",
    "            # Add the trace for the current category\n",
    "            fig.add_trace(go.Bar(\n",
    "                y=category_data[\"cellTypes\"],  # Categories for y-axis\n",
    "                x=category_data[\"expr_val\"],  # Expression values for x-axis\n",
    "                orientation='h',  # Horizontal bars\n",
    "                marker=dict(color=color),\n",
    "                hovertemplate=\n",
    "                    '<b>%{y}</b><br>' +  # Cell type (y-axis value)\n",
    "                    'Expression Value: %{x}',  # Expression value (x-axis value)\n",
    "                    #'Category: %{text}',  # Custom text (cell category)\n",
    "                #text=category_data[\"cellCategory\"],  # Pass the cell category as custom text\n",
    "                name=category,  # Use the category name for the legend\n",
    "                showlegend=True,  # Ensure the legend is shown for this trace\n",
    "            ))\n",
    "\n",
    "        # Update layout settings\n",
    "        fig.update_layout(\n",
    "            title=\"\",\n",
    "            xaxis_title=\"log(x+1) Expression value\",\n",
    "            yaxis_title=\"Cell Types\",\n",
    "            yaxis=dict(\n",
    "                tickmode='array',\n",
    "                tickvals=np.arange(num_bars),\n",
    "                ticktext=sub_df[\"cellTypes\"],\n",
    "                tickangle=0,  # Avoid overlapping labels by setting the angle to 0\n",
    "                tickfont=dict(size=6),  # Set font size for the labels\n",
    "            ),\n",
    "            showlegend=True,\n",
    "            legend_title=\"Cell Category\",\n",
    "            legend=dict(\n",
    "                orientation=\"v\",  # Vertical legend\n",
    "                yanchor=\"top\",\n",
    "                y=1,\n",
    "                xanchor=\"\",\n",
    "                x=1.05,  # Position the legend outside of the plot area\n",
    "                font=dict(size=10)\n",
    "            ),\n",
    "            margin=dict(t=50, b=50, l=150, r=50),\n",
    "            height=min(1000, max(500, num_bars * 30)),  # Adjust plot height\n",
    "            plot_bgcolor='rgba(0,0,0,0)',  # Transparent background\n",
    "            paper_bgcolor='rgba(0,0,0,0)',  # Transparent paper background\n",
    "        )\n",
    "\n",
    "        # Save to HTML file\n",
    "        fig.write_html(f\"data/gene_expr_plots/{gene}.html\")\n",
    "\n",
    "\n",
    "plot_gene_expression(connectomeDB_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00571f7a-50f1-4901-b0f8-1e76d14e43c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'connectomeDB_long' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconnectomeDB_long\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'connectomeDB_long' is not defined"
     ]
    }
   ],
   "source": [
    "connectomeDB_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4b069-0370-424e-9b83-4caaefce586d",
   "metadata": {},
   "source": [
    "## Testing Liana+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c78bfa0-43b3-4857-9ca4-41dcd8a230e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "Downloading data from `https://omnipathdb.org/queries/enzsub?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/interactions?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/complexes?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/annotations?format=json`\n",
      "Downloading data from `https://omnipathdb.org/queries/intercell?format=json`\n",
      "Downloading data from `https://omnipathdb.org/about?format=text`\n"
     ]
    }
   ],
   "source": [
    "import liana as li\n",
    "import omnipath as op\n",
    "import decoupler as dc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bd3fd-d53d-4586-8d1e-09befbaa9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"src\"))  # Add src directory to path\n",
    "from createDataTable import gene_pair0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f681087-38ba-4cfa-a105-8707ff70ac5f",
   "metadata": {},
   "source": [
    "### Pathway Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bd553-c8df-4970-9811-435c46e2c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PROGENy pathways, we use decoupler as a proxy as it formats the data in a more convenient way\n",
    "progeny = dc.get_progeny(top=10000)\n",
    "progeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2a08f-d44b-48ce-8a26-4f74ec640a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pairs = gene_pair0[[\"Ligand\", \"Receptor\"]]\n",
    "lr_pairs.columns = lr_pairs.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4b57a-700a-4e04-9c95-f33719a4f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ba05e-8929-4434-a765-0d77b67d0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ligand-receptor geneset\n",
    "lr_progeny = li.rs.generate_lr_geneset(lr_pairs, progeny, lr_sep=\"^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fba45-e3f2-4e26-b1fb-6bd3ed8ebacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_progeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beaedff-b8b8-4c41-b8c7-7ead6e5403aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the pairs are missing\n",
    "len(lr_progeny[\"interaction\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e12dce-6c86-4006-b9ba-01a6924aa0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file=\"data/pathway_annotations_per_pair.csv\"\n",
    "lr_progeny.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e477d7b-ced3-41ea-b412-65d9936b6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "whichDB= 'DisGeNet'\n",
    "# A database of expression profiles related to human diseases, including cancer\n",
    "diseases = op.requests.Annotations.get(\n",
    "    resources = [whichDB]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb551b9f-add0-45ea-98f8-58c7f3fe8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd5feb-feee-4193-aabc-6da6257b0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases.to_csv(\"data/\" + whichDB + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34da1b-e119-4c62-bfd4-41770dd2d010",
   "metadata": {},
   "source": [
    "### Disease Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1056987-e2ca-495c-a03f-78d002b63302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DisGeNet\n",
    "diseases = op.requests.Annotations.get(\n",
    "    resources = ['DisGeNet']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3b1e6-9ceb-4782-9c00-ef11379f0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = diseases[['genesymbol', 'label', 'value']]\n",
    "diseases = diseases.pivot_table(index='genesymbol',\n",
    "                                columns='label', values='value',\n",
    "                                aggfunc=lambda x: '; '.join(x)).reset_index()\n",
    "diseases = diseases[['genesymbol', 'disease']]\n",
    "diseases['disease'] = diseases['disease'].str.split('; ')\n",
    "diseases = diseases.explode('disease')\n",
    "lr_diseases = li.rs.generate_lr_geneset(lr_pairs, diseases, source='disease', target='genesymbol', weight=None, lr_sep=\"^\")\n",
    "lr_diseases.sort_values(\"interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a5201-dd41-4519-ae48-68fc7e004828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the pairs are missing\n",
    "len(lr_diseases[\"interaction\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd738f5-cebd-49e2-be19-673450d33efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file=\"data/disease_annotations_per_pair.csv\"\n",
    "lr_diseases.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5cef07-a5eb-483d-8f28-ba9b65a5cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.requests.Annotations.resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afd8af-fa7d-4a3a-b4a5-9f67d1b42e86",
   "metadata": {},
   "source": [
    "### Get FASTA sequences for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7dd4db-bf07-4131-b3b5-f9611116cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"src\"))  # Add src directory to path\n",
    "from createDataTable import gene_pair0\n",
    "\n",
    "# Get all unique genes\n",
    "ligand_list = gene_pair0[\"Ligand\"].tolist()\n",
    "receptor_list = gene_pair0[\"Receptor\"].tolist()\n",
    "unique_genes = list(set(ligand_list + receptor_list))  # Combine and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afcc47-8c40-45e1-8e7a-1ee3adaf1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "# Input FASTA file\n",
    "fasta_file = \"data/uniprotkb_proteome_UP000005640_AND_revi_2025_03_27.fasta.gz\"\n",
    "\n",
    "# Regex pattern to extract details from header\n",
    "header_pattern = re.compile(r\"^>sp\\|(?P<uniprot_id>[A-Z0-9]+(?:-\\d+)?)\\|(?P<protein_name>.+?) OS=Homo sapiens OX=9606 GN=(?P<gene_name>[A-Za-z0-9-]+)\")\n",
    "\n",
    "# Store extracted data\n",
    "records = []\n",
    "\n",
    "# Read and parse the file\n",
    "with gzip.open(fasta_file, \"rt\") as f:\n",
    "    header = None\n",
    "    sequence = []\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line.startswith(\">\"):\n",
    "            # Store previous sequence if exists\n",
    "            if header and sequence:\n",
    "                isoform_type = \"Canonical\" if \"-\" not in header[\"uniprot_id\"] else \"Alternative Isoform\"\n",
    "                records.append([header[\"uniprot_id\"], header[\"gene_name\"], header[\"protein_name\"], isoform_type, \"\".join(sequence)])\n",
    "            \n",
    "            # Match new header\n",
    "            match = header_pattern.match(line)\n",
    "            if match:\n",
    "                header = match.groupdict()\n",
    "                sequence = []\n",
    "            else:\n",
    "                header = None\n",
    "        \n",
    "        elif header:\n",
    "            sequence.append(line)\n",
    "\n",
    "    # Add the last record\n",
    "    if header and sequence:\n",
    "        isoform_type = \"Canonical\" if \"-\" not in header[\"uniprot_id\"] else \"Alternative Isoform\"\n",
    "        records.append([header[\"uniprot_id\"], header[\"gene_name\"], header[\"protein_name\"], isoform_type, \"\".join(sequence)])\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(records, columns=[\"UniProt ID\", \"Gene Symbol\", \"Protein Name\", \"Isoform Type\", \"FASTA Sequence\"])\n",
    "\n",
    "# Save as TSV\n",
    "df.to_csv(\"data/human_uniprot_isoforms.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"✅ Extracted {len(df)} Homo sapiens protein sequences and saved to 'human_uniprot_isoforms.tsv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b854e6-20a7-4c04-9268-e7df424c9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Gene Symbol\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46458bdf-7f37-4f86-9d03-27b894f15faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_table(\"data/human_uniprot_isoforms.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602f29d-65b0-4cda-9f04-0b8ef3159a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e7d70-7f61-4786-bae3-759a8d509344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['UniProt ID', 'Gene Symbol', 'Isoform Type', 'FASTA Sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7aeca2-f763-4b85-8503-65921fc934aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a97936-a9d2-471d-b287-3482fcfd357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = gene_pair0[[\"Human LR Pair\", \"Ligand\", \"Receptor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f4d8c-b251-4174-84de-727cd77ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb66bb9-0275-442d-b5bb-de269e41642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = lim_df.merge(df, how='left', left_on='Ligand', right_on='Gene Symbol')\n",
    "lim_df = lim_df.drop(columns=[\"Gene Symbol\"])\n",
    "lim_df = lim_df.rename(columns={\"FASTA Sequence\": \"Ligand Sequence\",\n",
    "                                \"UniProt ID\": \"Ligand Isoform Uniprot ID\",\n",
    "                                \"Isoform Type\": \"Ligand Isoform Type\"})\n",
    "lim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f774d-e37e-4d24-b415-d0eccb1eccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = lim_df.merge(df, how='left', left_on='Receptor', right_on='Gene Symbol')\n",
    "lim_df = lim_df.drop(columns=[\"Gene Symbol\"])\n",
    "lim_df = lim_df.rename(columns={\"FASTA Sequence\": \"Receptor Sequence\",\n",
    "                                \"UniProt ID\": \"Receptor Isoform Uniprot ID\",\n",
    "                                \"Isoform Type\": \"Receptor Isoform Type\"})\n",
    "lim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e9511-4026-4ef3-866a-d52aabd55e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df.to_csv(\"data/LRpair_uniprot_sequences.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef772ddd-9d77-4557-a1e0-84605e6e084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Extract Gene Symbol Mapping from GTF\n",
    "gtf_file = \"data/gencode.v47.annotation.gtf.gz\"\n",
    "gene_map = {}\n",
    "\n",
    "# Read GTF file and extract gene_id -> gene_name mapping\n",
    "with gzip.open(gtf_file, \"rt\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):  # Skip comments\n",
    "            continue\n",
    "        \n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        if fields[2] == \"gene\":  # Only extract gene entries\n",
    "            info = {key.strip(): value.strip('\"') for key, value in re.findall(r'(\\S+) \"([^\"]+)\"', fields[8])}\n",
    "            if \"gene_id\" in info and \"gene_name\" in info:\n",
    "                gene_map[info[\"gene_id\"]] = info[\"gene_name\"]\n",
    "\n",
    "print(f\"✅ Extracted {len(gene_map)} gene mappings from GTF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251cc7d-871d-4d23-936a-20703a223ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Parse GENCODE Protein FASTA and Add Gene Symbols\n",
    "fasta_file = \"data/gencode.v47.pc_translations.fa.gz\"\n",
    "\n",
    "# Store extracted data\n",
    "records = []\n",
    "\n",
    "# Open the GENCODE FASTA file and parse sequences\n",
    "with gzip.open(fasta_file, \"rt\") as f:\n",
    "    header = None\n",
    "    sequence = []\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line.startswith(\">\"):\n",
    "            # Store previous sequence if exists\n",
    "            if header and sequence:\n",
    "                # Extract the Gene Symbol using the Gene ID\n",
    "                gene_symbol = gene_map.get(header[\"gene_id\"], \"Unknown\")\n",
    "                isoform_type = \"Canonical\" if \"-1\" in header[\"protein_id\"] else \"Alternative Isoform\"\n",
    "                \n",
    "                # Append the parsed data to records\n",
    "                records.append([header[\"protein_id\"], header[\"transcript_id\"], header[\"gene_id\"], gene_symbol, isoform_type, \"\".join(sequence)])\n",
    "            \n",
    "            # Split header by '|' and extract necessary fields\n",
    "            fields = line[1:].split(\"|\")  # Skip the '>' symbol and split by '|'\n",
    "            if len(fields) >= 6:\n",
    "                header = {\n",
    "                    \"protein_id\": fields[0], \n",
    "                    \"transcript_id\": fields[1], \n",
    "                    \"gene_id\": fields[2]  \n",
    "                }\n",
    "                sequence = []\n",
    "            else:\n",
    "                header = None\n",
    "        \n",
    "        elif header:\n",
    "            sequence.append(line)\n",
    "\n",
    "    # Add the last record if needed\n",
    "    if header and sequence:\n",
    "        gene_symbol = gene_map.get(header[\"gene_id\"], \"Unknown\")\n",
    "        isoform_type = \"Canonical\" if \"-1\" in header[\"protein_id\"] else \"Alternative Isoform\"\n",
    "        records.append([header[\"protein_id\"], header[\"transcript_id\"], header[\"gene_id\"], gene_symbol, isoform_type, \"\".join(sequence)])\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame and Save to TSV\n",
    "df = pd.DataFrame(records, columns=[\"Ensembl Protein ID\", \"Ensembl Transcript ID\", \"Ensembl Gene ID\", \"Gene Symbol\", \"Isoform Type\", \"FASTA Sequence\"])\n",
    "\n",
    "# Save to TSV\n",
    "df.to_csv(\"data/gencode_protein_isoforms_with_symbols.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Print completion message\n",
    "print(f\"✅ Extracted {len(df)} protein sequences with Gene Symbols and saved to 'gencode_protein_isoforms_with_symbols.tsv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e721088-e99d-4909-b523-8f334f3c8e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343d57b-9a88-4ade-89f2-9cdf0ce2ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = gene_pair0[[\"Human LR Pair\", \"Ligand\", \"Receptor\"]]\n",
    "lim_df = lim_df.merge(df, how='left', left_on='Ligand', right_on='Gene Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e760dccb-b0f6-41e5-a8fc-554eb1909cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1f428-00f5-4f40-8906-499ac5d8a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = lim_df.drop(columns=[\"Gene Symbol\"])\n",
    "lim_df = lim_df.rename(columns={\"FASTA Sequence\": \"Ligand Sequence\",\n",
    "                                \"Ensembl Protein ID\": \"Ligand Ensembl Protein ID\",\n",
    "                                \"Ensembl Transcript ID\": \"Ligand Ensembl Transcript ID\",\n",
    "                                \"Ensembl Gene ID\": \"Ligand Ensembl Gene ID\",\n",
    "                                \"Isoform Type\": \"Ligand Isoform Type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc88ddd-5476-4f3d-8fa8-815c0827f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd1035-ecfd-462c-a6d5-61b59da565e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df = lim_df.merge(df, how='left', left_on='Receptor', right_on='Gene Symbol')\n",
    "lim_df = lim_df.drop(columns=[\"Gene Symbol\"])\n",
    "lim_df = lim_df.rename(columns={\"FASTA Sequence\": \"Receptor Sequence\",\n",
    "                                \"Ensembl Protein ID\": \"Receptor Ensembl Protein ID\",\n",
    "                                \"Ensembl Transcript ID\": \"Receptor Ensembl Transcript ID\",\n",
    "                                \"Ensembl Gene ID\": \"Receptor Ensembl Gene ID\",\n",
    "                                \"Isoform Type\": \"Receptor Isoform Type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028f462-74cc-40d7-a7d3-003689e862f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf876e97-f9fa-4ca2-bf21-f82861e132ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_df.to_csv(\"data/LRpair_gencode_sequences.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995394a-d081-4971-be36-38240103bc32",
   "metadata": {},
   "source": [
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2253500-50d6-4759-9ca2-c282eb8e2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to scrape data from Pubmed for Title, Abstract, Journal, and Year\n",
    "### IMPORTANT: TURN OFF VPN and make sure you have the data directory (from Sakura)\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "sys.path.append(os.path.abspath(\"src\"))  \n",
    "import fetchGSheet\n",
    "\n",
    "# Read the API key from a file\n",
    "with open(\"data/ncbi_api_key.txt\", \"r\") as file:\n",
    "    ncbi_api_key = file.read().strip()\n",
    "\n",
    "# File to save the results\n",
    "output_file = \"data/pubmed_results.csv\"\n",
    "\n",
    "# Example of fetching HGNC gene symbols (you should have the `fetchGSheet.pop_up_info` dataframe ready)\n",
    "def extract_hgnc_symbols(fetchGSheet):\n",
    "    # Concatenate Approved, Alias, and Previous symbols, then extract unique symbols\n",
    "    hgnc_symbols = pd.concat([\n",
    "        fetchGSheet['Approved symbol'],\n",
    "        fetchGSheet['Alias symbol'],\n",
    "        fetchGSheet['Previous symbol']\n",
    "    ], axis=0).dropna().str.upper().unique()  # Remove NaNs and make uppercase for matching\n",
    "     # Remove any empty strings from the list\n",
    "    hgnc_symbols = [symbol for symbol in hgnc_symbols if symbol != \"\"]\n",
    "    return set(hgnc_symbols)  # Return as a set for fast lookup\n",
    "    \n",
    "hgnc_symbols = extract_hgnc_symbols(fetchGSheet.pop_up_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a012dcd5-7fe8-4289-ad32-6a5197f65484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100941"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hgnc_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48fc01-b7e3-4698-b8e8-a287dc069243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official species names and their corresponding terms (scientific names)\n",
    "# Load your list of PMIDs\n",
    "pmid_list = source\n",
    "species_dict = {\n",
    "    \"human\": \"Homo sapiens\",\n",
    "    \"mouse\": \"Mus musculus\",\n",
    "    \"rat\": \"Rattus norvegicus\",\n",
    "    \"rabbit\": \"Oryctolagus cuniculus\",\n",
    "    \"monkey\": \"Macaca spp.\",\n",
    "    \"dog\": \"Canis lupus familiaris\",\n",
    "    \"pig\": \"Sus scrofa\",\n",
    "    \"zebra fish\": \"Danio rerio\",\n",
    "    \"chicken\": \"Gallus gallus\",\n",
    "    \"horse\": \"Equus ferus caballus\",\n",
    "    \"cat\": \"Felis catus\",\n",
    "    \"sheep\": \"Ovis aries\",\n",
    "    \"cow\": \"Bos taurus\",\n",
    "    \"fruit fly\": \"Drosophila melanogaster\",\n",
    "    \"c. elegans\": \"Caenorhabditis elegans\",\n",
    "}\n",
    "\n",
    "def fetch_pubmed_data(pmid_list, hgnc_symbols):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    results = []\n",
    "\n",
    "    # Load existing data if output file exists\n",
    "    if os.path.exists(output_file):\n",
    "        existing_data = pd.read_csv(output_file)\n",
    "    else:\n",
    "        existing_data = pd.DataFrame(columns=[\"PMID\", \"Title\", \"Abstract\", \"Journal\", \"Year\", \"Species\"])\n",
    "\n",
    "    # Split PMIDs into batches\n",
    "    batch_size = 50\n",
    "    pmid_batches = [pmid_list[i:i + batch_size] for i in range(0, len(pmid_list), batch_size)]\n",
    "\n",
    "    # Iterate over the batches\n",
    "    for batch in pmid_batches:\n",
    "        params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"id\": \",\".join(batch),  # Join PMIDs as comma-separated\n",
    "            \"retmode\": \"xml\",\n",
    "            \"api_key\": ncbi_api_key\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse the XML response\n",
    "            root = ET.fromstring(response.text)\n",
    "            for article in root.findall(\".//PubmedArticle\"):\n",
    "                # Extract Title and Abstract\n",
    "                title = article.findtext(\".//ArticleTitle\", default=\"N/A\")\n",
    "                abstract = article.findtext(\".//AbstractText\", default=\"No abstract available\")\n",
    "\n",
    "                # Extract Journal Title\n",
    "                journal_tag = article.find(\".//Journal/Title\")\n",
    "                journal = journal_tag.text.strip() if journal_tag is not None and journal_tag.text else \"N/A\"\n",
    "\n",
    "                # Extract Publication Year\n",
    "                pub_date = article.find(\".//PubDate\")\n",
    "                if pub_date is not None:\n",
    "                    year_tag = pub_date.find(\"Year\")\n",
    "                    year = year_tag.text if year_tag is not None else \"N/A\"\n",
    "\n",
    "                    # Fallback to MedlineDate if Year is missing\n",
    "                    if year == \"N/A\":\n",
    "                        medline_date_tag = pub_date.find(\"MedlineDate\")\n",
    "                        year = medline_date_tag.text.split()[0] if medline_date_tag is not None else \"N/A\"\n",
    "                else:\n",
    "                    year = \"N/A\"  # PubDate is completely missing\n",
    "\n",
    "                # Initialize species as N/A\n",
    "                species = \"N/A\"\n",
    "\n",
    "                # Check if the word \"patient\" is detected in title or abstract (assume human)\n",
    "                if \"patient\" in title.lower() or \"patient\" in abstract.lower():\n",
    "                    species = \"Homo sapiens\"\n",
    "                elif \"human\" in title.lower() or \"human\" in abstract.lower():\n",
    "                    species = \"Homo sapiens\"\n",
    "                else:\n",
    "                    # Look for HGNC gene symbols in title or abstract (assume human if found)\n",
    "                    for gene in hgnc_symbols:\n",
    "                        if gene in title or gene in abstract:\n",
    "                            species = \"Homo sapiens\"\n",
    "                            break\n",
    "                    else:\n",
    "                        # Look for MeSH terms related to species\n",
    "                        for mesh_heading in article.findall(\".//MeshHeadingList/MeshHeading\"):\n",
    "                            descriptor_name = mesh_heading.findtext(\"DescriptorName\")\n",
    "                            if descriptor_name:\n",
    "                                # Match official species names using the species_dict\n",
    "                                for species_term, scientific_name in species_dict.items():\n",
    "                                    if species_term in descriptor_name.lower():\n",
    "                                        species = scientific_name\n",
    "                                        break  # Stop after finding the first match\n",
    "\n",
    "                # Append the result\n",
    "                results.append({\n",
    "                    \"PMID\": article.findtext(\".//MedlineCitation/PMID\"),\n",
    "                    \"Title\": title,\n",
    "                    \"Abstract\": abstract,\n",
    "                    \"Journal\": journal,\n",
    "                    \"Year\": year,\n",
    "                    \"Species\": species\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching batch {batch}: {e}\")\n",
    "            # Optionally save the response for debugging\n",
    "            with open(f\"error_batch_{batch[0]}_{batch[-1]}.xml\", \"w\") as f:\n",
    "                f.write(response.text)\n",
    "\n",
    "        # Rate limiting to avoid API overload\n",
    "        time.sleep(1)  # Increase delay for better API compliance\n",
    "\n",
    "    # Save results\n",
    "    new_data = pd.DataFrame(results)\n",
    "    if not new_data.empty:\n",
    "        # Merge existing and new data, updating missing values\n",
    "        updated_data = pd.concat([existing_data, new_data])\n",
    "\n",
    "        # Ensure all PMIDs are strings\n",
    "        updated_data[\"PMID\"] = updated_data[\"PMID\"].astype(str)\n",
    "\n",
    "        # Drop rows with missing PMIDs\n",
    "        updated_data = updated_data.dropna(subset=[\"PMID\"])\n",
    "\n",
    "        # Ensure rows are ordered and remove duplicates\n",
    "        updated_data = (\n",
    "            updated_data.sort_values(by=\"PMID\")  # Ensure rows are ordered\n",
    "            .drop_duplicates(subset=\"PMID\", keep=\"last\")  # Keep the latest data\n",
    "        )\n",
    "        updated_data[\"Journal\"] = updated_data[\"Journal\"].str.split(\" (\", n=1, expand=False, regex=False).str[0]\n",
    "        updated_data.to_csv(output_file, index=False)\n",
    "    else:\n",
    "        print(\"No new data fetched.\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Fetch PubMed data with your list of PMIDs, output file path, and NCBI API key\n",
    "fetch_pubmed_data(pmid_list, hgnc_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f83505-39a9-42ef-8878-89f5044b1ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quarto_llm_env",
   "language": "python",
   "name": "quarto_llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
